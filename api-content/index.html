{"posts":[{"title":"数据库备份脚本","content":"1.Oracle RMAN 备份 1.1 创建目录 [oracle@OEL7 ~]$ mkdir -p /u01/dbbak/script [oracle@OEL7 ~]$ cd /u01/dbbak [oracle@OEL7 ~]$ chown -R oracle:oinstall script [oracle@OEL7 ~]$ mkdir -p /u01/dbbak/db [oracle@OEL7 ~]$ mkdir -p /u01/dbbak/arch [oracle@OEL7 ~]$ cd /u01/dbbak [oracle@OEL7 ~]$ chown -R oracle:oinstall db [oracle@OEL7 ~]$ chown -R oracle:oinstall arch 1.2 编辑脚本 [oracle@OEL7 ~]$ vi /u01/dbbak/script/rman_full.sh export ORACLE_HOME=/u01/app/oracle/product/19.0.0/dbhome_1 export ORACLE_SID=prod dt=`date '+%Y%m%d_%H%M%S'` /u01/app/oracle/product/19.3.0/dbhome_1/bin/rman target / cmdfile=/u01/dbbak/script/backup.sh log=/u01/dbbak/log/log_$dt.log append [oracle@OEL7 ~]$ vi /u01/dbbak/script/backup.sh run{ allocate channel c1 type disk; allocate channel c2 type disk; allocate channel c3 type disk; allocate channel c4 type disk; backup as compressed backupset database format '/u01/dbbak/db/DB%U.bkp' plus archivelog format '/u01/dbbak/arch/ARCH%U.bkp' delete all input; release channel c1; release channel c2; release channel c3; release channel c4; report obsolete; crosscheck copy; crosscheck archivelog all; delete noprompt obsolete; crosscheck backup; delete noprompt expired backup; } quit; EOF 1.3 脚本授权 [oracle@OEL7 ~]$ chmod 775 /u01/dbbak/script/backup.sh [oracle@OEL7 ~]$ chmod 775 /u01/dbbak/script/rman_full.sh 1.4 执行脚本 /u01/dbbak/script/rman_full.sh 1.5 定时任务 crontab -e 为编辑窗口 [oracle@OEL7 ~]$ crontab -l 0 2 * * * /u01/dbbak/script/rman_full.sh 1.6 备份删除 [oracle@OEL7 ~]$ rman target / RMAN&gt; show all; --备份策略调整，备份保留7天 CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 7 DAYS; 2.Oracle 逻辑备份 2.1 生成目录 [oracle@OEL7 ~]$ mkdir -p /home/oracle/backup/dump [oracle@OEL7 ~]$ mkdir -p /home/oracle/backup/tars #使用expdp时需要先指定转储文件和日志文件所在的目录，可以通过如下命令实现 SQL&gt; CREATE OR REPLACE DIRECTORY scott_backup as '/home/oracle/backup/dump'; SQL&gt; grant read,write on directory scott_backup to public; 2.2 备份脚本 [oracle@OEL7 ~]$ vi /home/oracle/backup/exp_backup.sh #!/bin/bash #Oracle 环境变量 NLS_LANG=AMERICAN_AMERICA.AL32UTF8 ORACLE_SID=prod ORACLE_BASE=/opt/oracle ORACLE_HOME=/opt/oracle/11g PATH=$PATH:$ORACLE_HOME/bin:$HOME/bin export ORACLE_SID ORACLE_BASE ORACLE_HOME NLS_LANG PATH #获取时间戳 #dump生成时间 export BAKUPTIME=`date +%Y%m%d%H%M%S` #压缩文件存放目录 export DATA_DIR=/home/oracle/backup/dump export TAR_DIR=/home/oracle/backup/tars cd $DATA_DIR echo &quot;Starting bakup...&quot; echo &quot;Bakup file path $DATA_DIR/scott_expdp_$BAKUPTIME.dmp&quot; #parallel=4 为并行度，对于备份大数据库有助于减少备份时间，但会增加CPU负载。 expdp scott/tiger directory=scott_backup dumpfile=scott_expdp_$BAKUPTIME.dump logfile=scott_expdp_$BAKUPTIME.log parallel=4 echo &quot;Starting tar...&quot; echo &quot;Tar file path $TAR_DIR/SCOTT_$BAKUPTIME.tar.gz&quot; tar -zcvf $TAR_DIR/scott_expdp_$BAKUPTIME.tar.gz scott_expdp* echo &quot;Bakup job is done!&quot; #历史dump文件保留7天 find $DATA_DIR -type f -mtime +7 -exec rm -rf {} \\; 2.3 定时任务 crontab -e 为编辑窗口 [oracle@OEL7 ~]$ crontab -l 0 3 * * * /home/oracle/backup/exp_backup.sh 3.MySQL 逻辑全｜增备份 3.1 开启 binlog 日志 binlog日志默认不开启，修改参数后重启MySQL数据库 mysql&gt; show variables like '%log_bin%'; # vim /etc/my.cnf log_bin=ON log_bin_basename=/home/mysql/mysql-bin log_bin_index=/home/mysql/mysql-bin.index ## 参数说明 log_bin：开启binlog日志文件，默认值为OFF。 log_bin_basename：binlog日志的基本文件名。MySQL会在该文件名后追加标识来表示每一个binlog文件。 log_bin_index：binlog文件的索引文件，管理所有的binlog文件。 3.2 全备脚本 # mkdir -p /home/mysql/daily # mkdir -p /home/mysql/backup # vi /home/mysql/Mysql-FullyBak.sh #mysqldump to Fully backup mysql data per week! source /etc/profile BakDir=/home/mysql/backup LogFile=/home/mysql/backup/bak.log Date=`date +%Y%m%d` Begin=`date +&quot;%Y年%m月%d日 %H:%M:%S&quot;` cd $BakDir DumpFile=$Date.sql GZDumpFile=$Date.sql.tgz /usr/bin/mysqldump -uroot -proot --quick --events --databases wmp --flush-logs --delete-master-logs --single-transaction &gt;$DumpFile /bin/tar -zvcf $GZDumpFile $DumpFile /bin/rm $DumpFile oldDate=`date -d '7 days ago' +%Y%m%d` oldBakFile=${oldDate}&quot;.sql.tgz&quot; /bin/rm $oldBakFile Last=`date +&quot;%Y年%m月%d日 %H:%M:%S&quot;` echo 开始:$Begin 结束:$Last $GZDumpFile succ &gt;&gt; $LogFile cd $BakDir/daily /bin/rm -f * 3.3 增备脚本 # vi /home/mysql/Mysql-DailyBak.sh #use cp to bakup mysql data everyday! source /etc/profile BakDir=/home/mysql/backup/daily BinDir=/home/mysql/mysql-bin LogFile=/home/mysql/backup/bak.log BinFile=/home/mysql/mysql-bin/mysql-bin.index /usr/bin/mysqladmin -uroot -proot flush-logs Counter=`wc -l $BinFile |awk '{print $1}'` #产生新的mysql-bin.00000*文件 NextNum=0 #比对$Counter和￥NextNum这两个值来确定文件是不是最新的 for file in `cat $BinFile` do base=`basename $file` #basename用于截取mysql-bin.00000*文件名，去掉./mysql-bin.000005前面的./ NextNum=`expr $NextNum + 1` if [[ $NextNum -eq $Counter ]] then echo $base skip! &gt;&gt; $LogFile else dest=$BakDir/$base if(test -e $dest) #test -e用于检测目标文件是否存在，存在就写exist!到$LogFile去 then echo $base exist! &gt;&gt; $LogFile else cp $BinDir/$base $BakDir echo $base copying &gt;&gt; $LogFile fi fi done 3.4 定时任务 在命令行输入: #crontab -e 添加相应的任务，wq存盘退出 #每个星期日凌晨3:00执行完全备份脚本 0 3 * * 0 /bin/bash -x /home/mysql/Mysql-FullyBak.sh &gt;/dev/null 2&gt;&amp;1 #周一到周六凌晨3:00做增量备份 0 3 * * 1-6 /bin/bash -x /home/mysql/Mysql-DailyBak.sh &gt;/dev/null 2&gt;&amp;1 3.5 恢复步骤 4.MySQL PXB 全 / 增备份 Xtrabackup 是一个开源的 MySQL 数据库备份工具，由 Percona 公司开发和维护 4.1 备份脚本 vi /home/mysql/scripts/backup.sh #!/bin/bash echo &quot;&quot; START_TIME=`date` echo &quot;############## backup start at $START_TIME ##############&quot; echo &quot;&quot; ###you need install xtrabackup!### # Set env source /home/mysql/.bash_profile which xtrabackup # Database Info DB_USER=&quot;root&quot; DB_PASS=&quot;jeames@123&quot; CONF=&quot;/data/mysqldb/conf/mysql.conf&quot; SOCKET=&quot;/data/mysqldb/socket/mysql.sock&quot; BAK_BASE=&quot;/db_bak/mysql_bak/mysql&quot; DATE=`date +%F` YESTERDAY=`date +%F -d &quot;-1 days&quot;` WEEK_DAY=`date +%w` BAK_DIR=$BAK_BASE/$DATE-$WEEK_DAY # Create Directory and backup if [ &quot;$WEEK_DAY&quot; == &quot;6&quot; ]; then xtrabackup --defaults-file=$CONF --socket=$SOCKET --backup --user=$DB_USER --password=$DB_PASS --target-dir=$BAK_DIR --compress elif [ &quot;$WEEK_DAY&quot; == &quot;0&quot; ]; then INCRE_BASE=$BAK_BASE/$YESTERDAY-6 xtrabackup --defaults-file=$CONF --socket=$SOCKET --backup --user=$DB_USER --password=$DB_PASS --target-dir=$BAK_DIR --incremental-basedir=$INCRE_BASE --compress else INCRE_BASE=$BAK_BASE/$YESTERDAY-$[WEEK_DAY-1] xtrabackup --defaults-file=$CONF --socket=$SOCKET --backup --user=$DB_USER --password=$DB_PASS --target-dir=$BAK_DIR --incremental-basedir=$INCRE_BASE --compress fi echo &quot;&quot; END_TIME=`date` echo &quot;############## backup end at $END_TIME ##############&quot; echo &quot;&quot; 4.2 备份删除 vi /home/mysql/scripts/cleanup.sh #!/bin/bash echo &quot;&quot; START_TIME=`date` echo &quot;############## clean up start at $START_TIME ##############&quot; echo &quot;&quot; find /db_bak/mysql_bak/mysql -maxdepth 1 -type d -mtime +30 find /db_bak/mysql_bak/mysql -maxdepth 1 -type d -mtime +30 -exec rm -rf {} \\; echo &quot;&quot; END_TIME=`date` echo &quot;############## clean up end at $END_TIME ##############&quot; echo &quot;&quot; 4.3 定时任务 运行脚本 每天凌晨 4:10 分清理 30 天之前的备份， 每天 4:30 分使用 xtrabackup 进行备份， 注意只有周六是全备，其他时间均是增备。 #crontab -e 10 4 * * * /home/mysql/scripts/cleanup.sh &gt;&gt; /home/mysql/scripts/cleanup.log 2&gt;&amp;1 30 4 * * * /home/mysql/scripts/backup.sh &gt;&gt; /home/mysql/scripts/backup.log 2&gt;&amp;1 5.PostgreSQL 逻辑备份 以下是一个用于定时备份 PostgreSQL 数据库的示例脚本。这个脚本将使用 pg_dump 工具来创建数据库备份，然后将备份文件保存到指定的目录中，并可选择保留最近一段时间内的备份文件 5.1 备份脚本 vi /data/script_name.sh #!/bin/bash # PostgreSQL数据库相关信息 db_host=&quot;localhost&quot; db_port=&quot;5432&quot; db_ db_user=&quot;database_user&quot; db_password=&quot;database_password&quot; # 备份存储目录 backup_dir=&quot;/data/backup/folder&quot; # 保留备份的天数 retention_days=7 # 创建备份目录 mkdir -p $backup_dir # 备份文件名 backup_file=&quot;$backup_dir/backup_$(date +'%Y%m%d%H%M%S').sql&quot; # 执行备份 PGPASSWORD=$db_password pg_dump -h $db_host -p $db_port -U $db_user -F c -b -v -f &quot;$backup_file&quot; $db_name if [ $? -eq 0 ]; then echo &quot;数据库备份成功: $backup_file&quot; # 删除旧的备份文件 find $backup_dir -name &quot;backup_*.sql&quot; -type f -mtime +$retention_days -exec rm -f {} \\; else echo &quot;数据库备份失败.&quot; fi 5.2 定时任务 在命令行输入: #crontab -e #每天定时凌晨2点定时任务 0 2 * * * /data/script_name.sh 5.3 备份恢复 --恢复 drop database jmedb; create database jmedb;; psql --file=jmedb.sql --先查看可否有创建数据库的语句 psql --dbname=db2 --file=jmedb.sql --先查看可否有创建数据库的语句 6.PostgreSQL 物理备份 pg_rman 是一个开源的 PostgreSQL 备份软件,pg_rman 跑的不是流复制协议，而是文件拷贝，所以 pg_rman 必须和数据库 Server 安装在一起. 6.1 备份脚本 #!/bin/bash source /home/postgres/.bash_profile DATE=`date +%Y%m%d`; PG_HOME=/home/postgres BACK_LOG=/home/postgres/log/pg_rman_${DATE}.log #START BACKUP echo &quot;START BACKUP&quot; &gt; $BACK_LOG #执行备份命令 pg_rman backup --backup-mode=full -B /rmanbk &gt;&gt; $BACK_LOG #备份集校验 pg_rman validate &gt;&gt; $BACK_LOG #检查备份是否成功 error_num=`pg_rman show | awk 'BEGIN{n=0}{if(NR &gt; 3 &amp;&amp; $8 != &quot;OK&quot;)n++}END{print n}'` if [ $error_num &gt; 0 ];then message=&quot;Postgres 数据库服务器${hostname}在${DATE}备份失败&quot; echo $message fi #清理无效备份集 pg_rman purge &gt;&gt; $BACK_LOG echo &quot;BACKUP END&quot; &gt;&gt; $BACK_LOG 6.2 备份恢复 --原地恢复,使用新的$PGDATA恢复 pg_ctl stop rm -rf /postgresql/pgdata/ pg_rman restore -B /rmanbk -- 检查配置文件是否有问题，若无问题则可以启动PG pg_ctl start --检验数据是否正确 启动PG后，会删除recovery.signal文件 7.openGauss 备份 7.1 备份脚本 vi /home/omm/backup.sh # database dump shell # you should change the GAUSSHOME GAUSSPORT GAUSSDATA DUMP_USER DUMP_PASSWORD #!/bin/bash source /etc/profile source /home/omm/.bash_profile export GAUSSHOME=/opt/gaussdb/app export GAUSSPORT=26000 export GAUSSDATA=/gaussdb/data/dn1 export PATH=$PGHOME/bin:$PATH DUMP_USER=ysla DUMP_PASSWORD='jeames007@HW' CUR_DATE=`date &quot;+%Y-%m-%d-%H%M&quot;` dbnamelist=`cat db.txt` #Loading DBLIST gsql -p ${GAUSSPORT} postgres -c &quot;select datname from pg_database where datname not in ('template1','template0','postgres')&quot; -t | grep -v '^$' &gt;db.txt #save directory SAVE_BASE_DIR=&quot;/gaussdb/dump_dir&quot; DAT_FILE_DIR=&quot;${SAVE_BASE_DIR}/${CUR_DATE}&quot; if [ -d ${DAT_FILE_DIR} ] then : else mkdir -p ${DAT_FILE_DIR} fi # The real backup step! echo &quot;`date &quot;+%Y-%m-%d-%H%M&quot;` begin backup db &quot; for dbname in ${dbnamelist} do gs_dump -E UTF8 ${dbname} -U ${DUMP_USER} -W ${DUMP_PASSWORD} -p ${GAUSSPORT} -F p -f ${DAT_FILE_DIR}/${dbname}_${CUR_DATE}.sql gs_dumpall -l ${dbname} -U ${DUMP_USER} -W ${DUMP_PASSWORD} -p ${GAUSSPORT} -g -f ${DAT_FILE_DIR}/global_data_${dbname}_${CUR_DATE}.sql done tar -cjvf ${DAT_FILE_DIR}.tar.gz /${DAT_FILE_DIR} --remove-files echo &quot;`date &quot;+%Y-%m-%d-%H%M&quot;` end backup db &quot; 7.2 定时任务 在命令行输入: #crontab -e 30 02 * * * sh /home/omm/backup.sh 7.3 备份清理 每天都进行备份，如果备份天数过多不清理， 可能使目录打满，因此需要添加备份清理策略 在命令行输入: #crontab -e 30 03 * * * find /gaussdb/dump_dir -not -path '*/\\.*' -mtime +30 -type f -name *.tar.gz -exec rm -rf {} \\; log-bak.sh #!/bin/bash File=/var/log/messages BackDir=/work/log-bak Data=`date +%F` IpNumbers=$(awk '{print $4}' $File|uniq -c|awk '{a[$2]+=$1}END{for(i in a) print i}') cp $File $BackDir/logs/messages.$Data echo &quot;&quot;&gt;$File cp /var/log/secure $BackDir/logs/secure.$Data echo &quot;&quot;&gt;/var/log/secure for ip in $IpNumbers do [ ! -d $BackDir/ipsub/$ip ] &amp;&amp; mkdir $BackDir/ipsub/$ip grep $ip $BackDir/logs/messages.$Data &gt;&gt;$BackDir/ipsub/$ip/`date +%F`.messages grep $ip $BackDir/logs/secure.$Data &gt;&gt;$BackDir/ipsub/$ip/`date +%F`.secure done MySQL 数据库备份单循环 #!/bin/bash DATE=$(date +%F_%H-%M-%S) HOST=localhost USER=backup PASS=123.com BACKUP_DIR=/data/db_backup DB_LIST=$(mysql -h$HOST -u$USER -p$PASS -s -e &quot;show databases;&quot; 2&gt;/dev/null |egrep -v &quot;Database|information_schema|mysql|performance_schema|sys&quot;) for DB in $DB_LIST; do BACKUP_NAME=$BACKUP_DIR/${DB}_${DATE}.sql if ! mysqldump -h$HOST -u$USER -p$PASS -B $DB &gt; $BACKUP_NAME 2&gt;/dev/null; then echo &quot;$BACKUP_NAME 备份失败!&quot; fi done ","link":"https://pandajackpragrammer.github.io/post/shu-ju-ku-bei-fen-jiao-ben/"},{"title":"❤️Docker 中只需 2 步即可拥有 Oracle 11G 企业版环境, 史上最快部署❤️","content":"简介： ❤️Docker 中只需 2 步即可拥有 Oracle 11G 企业版环境, 史上最快部署❤️ 下载镜像 邦德的Docker Hub主页：https://hub.docker.com/u/techerwang oracle 11g 11.2.0.4 DB的地址：https://hub.docker.com/r/techerwang/oracle/tags #从Docker hub下载，网络不好时，一般比较慢 docker pull techerwang/oracle:ora11g11204 #可以选择从阿里云下载 docker pull registry.cn-shanghai.aliyuncs.com/techerwang/oracle:ora11g11204 镜像大概3.2G左右，解压后大约7.6G左右，所以请保留充足的空间 #从阿里云下载后可以tag成如下形式： docker tag registry.cn-shanghai.aliyuncs.com/techerwang/oracle:ora11g11204 jemora11g:11204 docker images | grep 11g 创建容器并启动数据库 2.1 创建容器 docker run -itd --name jemora11204 -h jemora11204 \\ --privileged=true -p 21521:1521 -p 222:22 -p 21158:1158 \\ jemora11g:11204 init 2.2 进入容器 [root@jeames ~]# docker exec -it jemora11204 bash 2.3 启动数据库和监听 [root@jemora11204 /]# su - oracle [oracle@jemora11204 ~]$ lsnrctl start [oracle@jemora11204 ~]$ sqlplus / as sysdba SYS@JEM11G2&gt; startup SYS@JEM11G2&gt; select * from v$version; 外部连接容器内的数据库 sqlplus sys/jem@192.168.1.54:21521/JEM11GR2 AS SYSDBA 如果使用 PLSQL Developer 也是可以连接的，如下： 注意：此处访问宿主机端口为 21521 哈，容器内部是 1521，端口器映射, 系统管理员密码为 jem ","link":"https://pandajackpragrammer.github.io/post/docker-oracle-11g/"},{"title":"ETL工具Kettle的使用方法","content":"一、Kettle 简介 1.1、Kettle 是什么 Kettle 是一款国外开源的 ETL 工具，纯 Java 编写，可以在 Window、Linux、Unix 上运行，绿色无需安装，数据抽取高效稳定。 Kettle 中文名称叫水壶，该项目的主程序员 MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。 Kettle 这个 ETL 工具集，它允许你管理来自不同数据库的数据，通过提供一个图形化的用户环境来描述你想做什么，而不是你想怎么做。 Kettle 中有两种脚本文件，Transformation 和 Job，transformation 完成针对数据的基础转换，Job 则完成整个工作流的控制。 Kettle，现在已经更名为 PDI（Pentaho Data Integration-Pentaho，即数据集成）。 1.2、Kettle 的特点 无代码拖拽式构建数据管道 Kettle 采用拖拽组件、连线、配置的方式来构建数据管道，透过超过 200 个不同的组件，用户可以在不编写一句代码就能轻松完成对数据源读取，对数据进行关联、过滤、格式转换、计算、统计、建模、挖掘、输出到不同的数据目标。极大程度地降低开发技术门槛和有效减低开发和维护成本。 多数据源对接 关系型数据库支持类型包括：AS/400，DB2，Google BigQuery，Greenplum，Hive，Impala，MS SQL Server，MySQL，Oracle，PostgreSQL，SAP，Snowflake，SparkSQL，Sybase，Teradata, Vertica 等。 大数据源支持包括：Avro，Cassanddra，HBase，HDFS，MongoDB，ORC, Parquet, Splunk 等。 文件格式支持包括：CSV, TXT, JSON, Excel, XML 等。 流数据支持包括：AMPQ，JMS，Kafka，Kinesis，MQTT。 其他数据源对接包括：HL7，S3，SAS，Salesforce，HCP，REST 等。 数据管道可视化 Kettle 支持用户在数据管道任何一个步骤对当前数据进行查看（Examine），并可以在线以表格和图表（例如：柱状图、饼图等）输出步骤的数据，甚至可以支持不落地直接把任何一个步骤的数据以 JDBC 的方式提供给第三方应用访问。 模板化开发数据管道 Kettle 提供了一个叫 MDI 的功能，MDI 全称是 Metadata Injection 元数据注入，用户可以透过 MDI 把数据转换模板化，然后把像数据表名、文件路径、分隔符、字符集等等这些变量放在一个表或者文件里，然后利用 MDI 把这些变量注入数据转换模板，Kettle 就能够自动生成所需要的数据转换了。这个功能为很多客户节省了大量的开发时间。 可视化计划任务 Kettle 提供可视化方式配置任务计划（Schedule），用户可透过 Spoon 或网页端的 Pentaho User Console 来配置和维护任务具体的执行时间、间隔、所使用的参数值、以及具体运行的服务器节点。 用户亦可以透过 Spoon 或 Pentaho User Console 查看任务计划列表；当然，用户也可以透过 Spoon 或 Pentaho User Console 对任务执行情况进行实时监控。 深度 Hadoop 支持 Kettle 针对 Hadoop 主流厂家预置专用的对接插件，支持的 Hadoop 版本包括 Cloudera，Hortonworks，AWS EMR，Google Dataproc 等，用户除了可以透过插件轻松对接 Hadoop 集群的数据源（HDFS，Hive，HBase，Impala 等）以外，Pentaho 还提供与 Kerberos、Sentry 和 Ranger 等 Hadoop 企业级安全机制对接，以满足企业安全要求。 另外，Pentaho Data Integration 的 Pentaho MapReduce 提供用户以无编码方式定义 MapReduce 任务；同时，用户亦可以在作业中执行 Sqoop、Pig、MapReduce、Oozie 和 Spark 任务。 数据任务下压 Spark 集群 Kettle 提供了把数据转换任务下压到 Spark 来执行的 **AEL（Adaptive Execution Layer）**功能，搭建好的数据管道会被 AEL 转成 Spark 任务来执行，这样数据就不需要离开集群，而是在集群里透过 Spark 强大的分布式处理能力来进行处理。 数据挖掘与机器学习支持 最新版的 Pentaho9.1 预置了超过 20 种数据挖掘算法类的转换步骤，用户可以轻松把把机器学习集成到数据管道里，用来做数据模型训练和进行预测分析。 预置算法包括：决策树、深度学习、线性回归、逻辑回归、Naive 贝尔斯、随机森林等等，用户也可以利用 Pentaho Data Integration 作数据预备，然后把数据以 dataframe 的方式输入到 Python 或 R 中进行模型训练或预测。 1.3、Kettle 核心组件 Spoon Spoon 是构建 ETL Jobs 和 Transformations 的工具。Spoon 以拖拽的方式图形化设计，能够通过 spoon 调用专用的数据集成引擎或者集群。 Pan Pan 是一个后台执行的程序，没有图形界面，类似于时间调度器。 chef 任务通过允许每个转换，任务，脚本等等，更有利于自动化更新数据仓库的复杂工作。 Kitchen 批量使用由 Chef 设计的任务。 二、Kettle 安装与部署 2.1、下载 Kettle 官方网址：Home - Hitachi Vantara，目前最新是 9.2 版本的。 进入官网后选择 –&gt;Data Integration，找到 Downloads，看到稳定版本为 Data Integration 8.2，选择进行下载即可。 2.2、安装 下载好的压缩包进行解压 打开解压之后的 data-integration 文件夹 Windows 系统，点击 Spoon.bat 运行；Linux 系统点击 Spoon.sh 运行 2.3、环境变量配置 因为 Kettle 是纯 Java 开发的，因此下载以后需要配置一下环境变量。需要先安装 JDK，准备好 Java 软件的运行环境，安装 jdk1.8 版本即可，具体操作可参考百度。 2.4、常见问题 启动 Kettle 后，页面右上角不出现 Connect。 解决方法：打开系统盘用户目录下的 repositories.xml 配置文件，将乱码内容删除，并删除. spoonrc 文件，重启 Kettle。 2、可视化界面 spoon.bat 打不开，JVM 提示不能正常启动 解决方法： 检查环境变量的配置 检查 JDK 版本，新版本最好用 1.6 以上 新安装了高版本 jdk，环境变量也没问题，但是 java -version 版本还是老的，那就检查一下原版本的的快捷方式 java.exe 还在不在，在的话就删掉。 以文本方式打开 spoon.bat ，修改内存配置 3、连接数据库找不到驱动问题（以 MySQL 为例） 提示错误： [mysql] : org.pentaho.di.core.exception.KettleDatabaseException: Error occured while trying to connect to the database Driver class ‘org.gjt.mm.mysql.Driver’ could not be found, make sure the ‘MySQL’ driver (jar file) is installed. org.gjt.mm.mysql.Driver 解决办法：把 mysql-connector-java-5.1.37-bin.jar 拷贝到 \\pdi-ce-6.0.1.0-386\\data-integration\\lib 下面，然后重新启动 spoon 即可。 三、Kettle 运行界面与基本概念 3.1、运行界面 3.2、基本概念 1）可视化编程 Kettle 可以被归类为可视化编程语言（Visual Programming Languages，VPL），因为 Kettle 可以使用图形化的方式定义复杂的 ETL 程序和工作流。 Kettle 里的图就是转换和作业。 可视化编程一直是 Kettle 里的核心概念，它可以让你快速构建复杂的 ETL 作业和减低维护工作量，它通过隐藏很多技术细节，使 IT 领域更贴近与商务领域。 2）转换（Transformation） 转换是 ETL 解决方案中最主要的部分，它处理抽取、转换、加载各种对数据行的操作。 转换包含一个或多个步骤（step），如读取文件、过滤数据行、数据清洗或将数据加载到数据库。 转换里的步骤通过**跳（hop）**来连接，跳定义一个单向通道，允许数据从一个步骤向另一个步骤流动。 在 Kettle 里，数据的单位是行，数据流就是数据行从一个步骤到另一个步骤的移动。 数据流有的时候也被称之为记录流。 3）步骤（Step） Kettle 里面的，Step 步骤（控件）是转换里的基本的组成部分。一个步骤有如下几个关键特性： 步骤需要有一个名字，这个名字在转换范围内唯一。 每个步骤都会读、写数据行（唯一例外是 “生成记录” 步骤，该步骤只写数据）。 步骤将数据写到与之相连的一个或多个输出跳，再传送到跳的另一端的步骤。 大多数的步骤都可以有多个输出跳。一个步骤的数据发送可以被被设置为分发和复制，分发是目标步骤轮流接收记录，复制是所有的记录被同时发送到所有的目标步骤。 4）跳（Hop） Kettle 里面的跳即步骤之间带箭头的连线，跳定义了步骤之间的数据通路。 跳实际上是两个步骤之间的被称之为行集的数据行缓存（行集的大小可以在转换的设置里定义）。 当行集满了，向行集写数据的步骤将停止写入，直到行集里又有了空间。 当行集空了，从行集读取数据的步骤停止读取，直到行集里又有可读的数据行。 5）数据行——数据类型 数据以数据行的形式沿着步骤移动。一个数据行是零到多个字段的集合，字段包含下面几种数据类型。 String：字符类型数据 Number：双精度浮点数。 Integer：带符号长整型（64 位）。 BigNumber：任意精度数据。 Date：带毫秒精度的日期时间值。 Boolean：取值为 true 和 false 的布尔值。 Binary：二进制字段可以包含图像、声音、视频及其他类型的二进制数据。 6）数据行——元数据 每个步骤在输出数据行时都有对字段的描述，这种描述就是数据行的元数据。通常包含下面一些信息。 名称：行里的字段名应用是唯一的。 数据类型：字段的数据类型。 格式：数据显示的方式，如 Integer 的 #、0.00。 长度：字符串的长度或者 BigNumber 类型的长度。 精度：BigNumber 数据类型的十进制精度。 货币符号：￥。 小数点符号: 十进制数据的小数点格式。不同文化背景下小数点符号是不同的，一般是点（.）或逗号（，）。 分组符号：数值类型数据的分组符号，不同文化背景下数字里的分组符号也是不同的，一般是点（.）或逗号（，）或单引号（’）。 **7）日志——**I O R W U E (I=669, O=0, R=0, W=668, U=0, E=0) I 是指当前 (步骤) 生成的记录（从表输入、文件读入） O 是指当前 (步骤) 输出的记录数（输出到文件、表） R 是指当前 (步骤) 从前一步骤读取的记录数 W 是指当前 (步骤) 向后面步骤抛出的记录数 U 是指当前 (步骤) 更新过的记录数 E 是指当前 (步骤) 处理的记录数 四、Kettle 读取 CSV 文件 4.1、输入 就是用来抽取数据或生成数据的操作。是 ETL 操作的 E(Extraction)。 4.2、CVS 文件 是一种带有固定格式的文本文件。 假设我们的目的是读取 CSV 文件，在 Excel 中输出。当然，这种简单操作完全不需要 Kettle，Excel 直接就可以打开并转换。练习的目的是从易到难，逐步掌握 Kettle 的用法。 CSV 文件是一种常见的文本文件，一般含有表头和行项目。大多数数据处理型软件都含有对 CSV 格式的支持。进入 Spoon 的主界面，通过菜单 [文件] –&gt; [新建] –&gt; [转换] 新建一个转换。 在左边的核心对象中，找到输入文件夹下面的 CSV 文件输入，将其拖到右边的工作区。双击 CSV 文件输入图标，通过浏览按钮找到 想要读取的 CSV 文件： 点击对话框中的 “获取字段” 按钮，自动获得 CSV 文件各列的表头。之所以可以这样，是因为 “包含列头行” 默认选中。点击 “预览” 按钮可以预览数据。如果是中文，注意文件的编码。 在左边导航区的 “输出” 文件夹下，将 “Excel 输出” 步骤拖放到右边的工作区。选中步骤 “CSV 文件输入”，通过 shift + 鼠标拖动，连接两个步骤，此时界面如下： 双击 “Excel 输出”，设置文件名和扩展名： 切换到 “字段” 页签，点击 “获取字段” 按钮，获取需要输出的字段，可以删除不想要的字段，然后点击 “确定” 按钮： 运行之前保存，转换被保存为扩展名为 ktr 的文件，这个文件是 xml 格式的文本文件，可以用 spoon 打开。然后点击 “运行”，即可以将 CSV 文件转换成 Excel 文件。 4.3、多个文件输入 在导航区 “核心对象” 中，找到 “输入” 文件夹下 “获取文件名”，拖到工作区。设置如下： 点击 “预览记录” 按钮，查看包含的文件，两个文件都被读取到。filename 是在下一步要使用的文件路径，属于输出的变量。 将 “获取文件名” 步骤连接至 “CSV 文件输入” 步骤。此时，“CSV 文件输入” 步骤的界面中，文件名字段为数据来源于前一步骤，选择 filename。其他相同。 运行，可以把两个 CSV 文件中的数据加载并输出到 Excel 文件中。输入的文件格式，比如文本文件、Excel 文件大体类似。 五、Kettle 导入文件夹下的多个文件 5.1、任务描述 在一个文件夹下有几百个文本文件，每个文件内容的格式相同，都是有固定分隔符的两列，每个文件有几千行记录。 Kettle 的转换处理数据流，其中有一个 “文本文件输入” 的输入对象，可以使用它在导入文件数据时添加上文件名字段，而且支持正则表达式同时获取多个文件名，正好适用此场景。 5.2、操作过程 1. 新建一个转换 包含 “获取文件名”、“拆分字段 2”、“拆分字段”、“表输出” 四个步骤，如下图所示。 2. “文本文件输入” 如下图所示。 正则表达式.test. 意思是查找以 test 开头的文件。 3. 拆分字段 按照分隔符 “|” 将字段 field_1 拆成 field_000 和 field_111 5. 表输出 6. 启动运行 六、Kettle 创建数据库连接 6.1、任务描述书 抽取数据库数据，第一步是创建数据库连接，为数据操作提供桥梁。 为了方便抽取 MySQL 的 “demodb” 数据库中的数据表，需要创建一个数据库连接，访问 “demodb” 数据库。 6.2、实现思路 建立数据库连接 设置数据库连接参数 测试和预览数据库连接 建立共享 / 停止共享数据库连接 6.3、操作过程 1）建立数据库连接 数据库连接必须在转换工程或任务工程中才能创建，使用 Ctrl+N 快捷键，首先创建【demodb 数据库连接】转换工程。 在【demodb 数据库连接】转换工程中，单击【主对象树】选项卡，展开【转换】对象数（按钮表示收起状态，按钮表示展开状态），右键单击【demodb 数据库连接】下的【DB 连接】对象，弹出快捷菜单。如图所示： 6.4、设置参数 单击【新建】选项，弹出创建【数据库连接】对话框。 数据库连接参数包含【一般】【高级】【选项】【连接池】和【集群】5 类参数。 其中，【一般】参数是必填项，多数情况只需进行【一般】参数设置，即可完成创建数据库连接，其他四项是可选项。 由于【高级】【选项】【连接池】绝大多数情况下采用默认值，一般不需要再设置其参数，本篇教程主要介绍【一般】参数和【集群】参数的设置。 1）【一般】参数 【一般】参数分为【连接名称】【连接类型】【连接方式】【设置】四部分参数设置。因为【连接类型】参数设置不同，【连接方式】【设置】参数设置也会有所不同，所以必须按照【连接类型】【连接方式】【设置】的顺序进行参数设置。 2）【集群】参数 指单个数据库连接能够连接抽取多个数据库的数据，单击【集群】参数项，进行【集群】参数设置。如图所示： 在【集群】参数设置中，勾选【使用集群】选项后，才能在【命名参数】表中设置集群参数。【分区 ID】参数是指用不同的 ID 名称标识各个数据库，可以是英文字母、数字、中文等字符或组合。 参数设置完之后，单击【测试】按钮，弹出数据库连接测试是否成功的对话框。若正确，则显示正确连接到数据库信息；若错误，则显示错误连接到数据库的信息，需要重新设置正确的参数。 七、Kettle 建立共享 / 停止共享数据库连接 为了避免反复创建相同的数据库连接，在多个不同的转换工程或作业任务中共用相同的数据库，可以考虑建立共享的数据库连接。 7.1、建立共享 在建立好的数据库连接装换工程中，单击【主对象树】选项卡，展开【转换】对象树，单击 &gt; 按钮，展开【DB 连接】对象，右键单击数据库连接的名称。 单击【共享】选项，数据库连接共享成功，其他转换工程或任务工程即可共享使用。需要注意的是，共享后的数据库连接名称为粗体字体显示。 7.2、停止共享 数据库连接既可以共享，也可以停止共享。 与共享操作类似，单击【主对象树】选项卡，在【转换】对象树中，单击 &gt; 按钮展开【DB 连接】对象，右键单击显示为粗体字体的数据库连接名称，在弹出快捷菜单中单击【停止共享】选项，即可停止共享该数据库连接。 八、Kettle 表输入 8.1、任务描述 数据表是指具有统一名称，并且类型、长度、格式等元素相同的数据集合，在数据库中，数据是以数据表的形式存储的。 表输入的作用是抽取数据库中的数据表，并获取表中的数据。 为方便查看和统计学生的数学考试分数，需要通过表输入抽取某年级某次考试的数据成绩。 8.2、实现思路 建立【表输入】转换工程 设置【表输入】组件参数 预览数据 8.3、操作过程 1）建立表输入转换工程 在 demodb 数据库中的 “数学成绩” 表，字段说明如表所示。 字段名称说明字段名称说明序号表示记录的顺序号数学表示数学考试分数学号表示学生在学校的唯一编号考试时间表示考试的日期和时间 使用 Ctrl+N 快捷键，创建【表输入】转换工程，对所使用到的表进行数据库连接创建操作，并测试结果为成功。 在【表输入】转换工程中，单击【核心对象】选项卡，展开【输入】对象，选中【表输入】组件，并拖拽到右边工作区中。 双击【表输入】组件，弹出【表输入】对话框，如图所示。 2）设置参数 在【表输入】对话框中，设置有关参数，获取 MySQL 的 demodb 数据库中的 “数学成绩” 表，步骤如下： 1）设置组件名称。设置【步骤名称】为默认值 “表输入”。 2）设置数据库连接。单击【数据库连接】下拉框，选择所创建的链接。 浏览数据表。单击【获得 SQL 查询语句…】按钮，弹出【数据库浏览器】对话框，单击按钮展开数据库，再单击俺就展开【表】数据表，显示所需要浏览的表（本教程以 demodbConn 数据库中的数学成绩表为例）。选择【数学成绩】表。 查看选中的数据表信息。单击【动作】按钮，弹出快捷菜单选项，可以分别预览数据库表的数据、记录数、表结构、生成 SQL 语句、裁剪表和查看表的有关信息等，如图所示。 确认获取数据表的 SQL 查询语句。单击【确定】按钮，弹出【问题?】对话框，显示【你想在 SQL 里面包含字段名吗?】提示信息，如图所示。 单击【否】按钮，在【SQL】表达式参数中获取的是简单的 SQL 查询语句，如图所示，其他参数采用默认值，此时完成【表输入】组件参数的设置。 8.4、预览结果数据 单击【预览】按钮，在弹出【输入预览记录数量】对话框中，预览记录数量采用默认值，单击【确认】按钮。弹出【预览数据】对话框，展示表输入的数据，如图所示。 九、Kettle Excel 输入 9.1、任务描述 Excel 采用表格的形式，数据展示直观，操作方便。 与文本文件不同，Excel 文件中采用工作表存储数据，一个文件有多张不同名称的工作表，分别存放相同字段或不同字段的数据。 为方便浏览表中的明细数据，需要通过 Excel 输入抽取相应的数据。 9.2、实现思路 建立【Excel 输入】转换工程。 设置【Excel 输入】组件参数。 预览结果数据。 9.3、操作过程 1）建立 Excel 输入转换工程 本教程以 “物理成绩. xls” 文件为例，字段说明如下表所示： 字段名称说明字段名称说明序号表示记录的顺序号物理表示物理考试分数学号表示学生在学校的唯一编号考试时间表示考试的日期和时间 使用 Ctrl+N 快捷键，创建【Excel 输入】转换工程，单击【核心对象】选项卡，展开【输入】对象，选中【Excel 输入】组件，并拖拽到右边工作区中，如图所示。 2）设置参数 双击【Excel 输入】组件，弹出【Excel 输入】对话框，其中显示默认的【文件】对话框，如图所示。 在【Excel 输入】对话框中，包含组件的基础参数，以及【文件】【工作表】【内容】【错误处理】【字段】【其他输出字段】6 个选项卡的参数。 在组件的基础参数中，【步骤名称】参数表示【Excel 输入】组件名称，在单个转换工程中，名称必须唯一，采用默认值 “Excel 输入”。 【文件】【工作表】【字段】选项卡的参数是必填项（没有设置参数时，选项卡名称签名会显示 “！”，表示是必填项，设置参数后“！” 会消失），并且必须按照【文件】【工作表】【字段】选项卡的顺序设置，其他为可选项。 【文件】选项卡参数 在【文件】选项卡中，设置参数，并导入 “物理成绩. xls” 文件，步骤如下： a）浏览导入 Excel 文件。单击【浏览 (B)…】按钮，在计算机上浏览并导入“物理成绩. xls” 文件，如图所示。 b）添加并编辑 Excel 文件。单击【增加】，将浏览导入至【文件或目录】输入框中的 “E:\\data \\ 物理成绩. xls” 文件，添加至【选中的文件】表中，如图所示。 如果选中的文件有问题，那么单击【删除】或【编辑】按钮，可对选中的 Excel 文件进行编辑。其中，单击【选中的文件】表的行号，再单击【删除】按钮，即可删除选中所在行的文件。 c）查看被选中的文件名称.。单击【显示文件名称…】按钮，弹出【文件读取】对话框，查看被选中读取的文件，如图所示。 重复上述 a）~ c）个步骤可添加多个 Excel 文件，并查看读取的文件名称。 另外，如果需要导入同一个目录下的多份名称类似的文件，如导入同一个目录下名称分别为 “物理成绩. xls”“物理成绩 1.xls” 和“物理成绩 2.xls”的文件，可以使用通配符的方式导入。 具体操作为，在【选中的文件】参数表中，在【文件或目录】输入框中键入 “E:\\data”，在【通配符号】输入框中输入 “物理成绩 *.\\xls”，可以一次性读入这 3 个文件，如图所示。 【工作表】选项卡参数 单击【工作表】选项卡，如图所示。 在【要读取的工作表列表】表中设置工作表参数，获取导入的 Excel 文件的工作表，【工作表】选项卡参数的说明如表所示。 参数名称说明工作表名称表示 Excel 文件的工作表名称。可以是一个 Excel 文件、多个工作表，也可以是多个 Excel 文件、多个工作表。不同的文件，工作表名称可以相同。默认值为空。起始行表示要读取的工作表中的开始行，行号是从 0 开始。默认值为空。起始列表示要读取的工作表中的开始列，列号是从 0 开始。默认值为空。 如果导入的 Excel 文件中的每个工作表的字段结构都相同，那么在【要读取的工作表列表】表中的第 1 行，不设置任何工作表名称（即【工作表名称】输入栏留空），只需设置第 1 行的【起始行】和【起始列】输入栏参数，这样的设置是读取所有的工作表，即第 1 行 将用于所有工作表。 在【工作表】选项卡中，设置导入的 Excel 文件的工作表参数，步骤如下： a）获取选中文件的工作表。单击【获取工作表名称…】按钮，弹出【输入列表】对话框，左边【可用项目】列表列出选中文件的所有工作表，如 “物理成绩. xls” 文件的 “Sheet1” 工作表，而右边【你的选择】列表列出被选中的工作表，如图所示。 b）选择工作表。在【输入列表】对话框中，单击中间的【&gt;】【&gt;&gt;】【&lt;】【&lt;&lt;】按钮，可以在左、右列表中，选中或移除工作表，有关按钮说明如表所示 按钮说明&gt;表示右移按钮，选择左边【可用项目】列表中一个工作表，移到右边【你的选择】列表中。&lt;表示左移按钮，将右边【你的选择】列表中的一个工作表移回到左边【可用项目】列表中，与【&gt;】按钮操作相反。&gt;&gt;表示右移批处理按钮，将左边【可用项目】列表中的所有工作表，移到右边【你的选择】列表中。&lt;&lt;表示左移批处理按钮，将右边【你的选择】列表中的所有工作表，移回到左边【可用项目】列表中，与【&gt;&gt;】按钮操作相反。 在【输入列表】对话框中，将左边【可用项目】工作表 “Sheet1” 选中移到右边【你的选择】表中。 c）设置选中的工作表参数。单击【确定】按钮，将【你的选择】列表选中的 “Sheet1” 工作表添加至【要读取的工作表列表】表中进行参数设置，【起始行】和【起始列】参数都设置为“0”，此时完成【工作表】选项卡参数的设置，如图所示。 【字段】选项卡参数 单击【字段】选项卡如图所示。 在【字段】选项卡中，设置 “物理成绩. xls” 文件中字段的参数，步骤如下。 a）获取字段。单击【获取头部数据的字段…】按钮，添加字段到【字段】表中设置字段参数，如图所示。 b）设置字段参数。对字段参数进行设置，如图所示，此时完成【字段】选项卡参数的设置。 需要说明的是，如果有些 Excel 文件的文件头部没有字段数据，那么系统会自动生成默认的字段名称，也可以重新编辑字段名称，字段的类型、长度等，字段的属性也可以进行编辑。 当获取字段后，【Excel 输入】对话框下方【预览记录】按键的字体显示为黑色，说明此时可以预览数据。 【内容】选项卡参数 单击【内容】选项卡，如图所示。 对读取 Excel 文件内容进行参数设置，一般按照缺省值配置，参数的说明如表所示。 参数名称说明头部表示对选中的工作表是否包含表头行。默认值为√。非空记录表示是否在输出中不出现空行（记录）。默认值为√。停在空记录表示当读取记录遇到空行时，选择是否停止读取文件的当前工作表。默认值为空。限制表示限制生成的记录数量。当设置为 0 时，结果不受限制。默认值为 0.编码表示读入的文本文件编码。第一次使用时，Kettle 会在系统中搜索可用的编码。使用 Unicode 的，请指定 UTF-8 或 UTF-16。默认值为 Kettle 系统的编码。 【错误处理】选项卡参数 单击【错误处理】选项卡，如图所示，可对获取 Excel 文件时产生的错误处理参数进行设置，检查和定位错误位置，一般按照缺省值配置。 【其他输出字段】选项卡参数 单击【其他输出字段】选项卡，如图所示。 对 Excel 文件的其他输出字段参数进行设置，用于指定处理文件的附加信息，默认值为空，一般按照缺省值配置，有关参数的说明如表所示。 字段参数说明文件名称字段表示指定完整的文件名称和扩展名的字段。默认值为空。工作表名称字段表示指定要使用的工作表名称的字段。默认值为空。表单的行号列表示指定要使用的当前工作表行号字段。默认值为空。行号列表示指定写入行数的字段。默认值为空。文件名字段表示指定文件名但没有路径信息、但有扩展名的字段。默认值为空。扩展字段表示指定文件名扩展名的字段。默认值为空。路径字段表示指定以操作系统格式包含路径的字段。默认值为空。文件大小字段表示指定文件数据大小的字段。默认值为空。是否为文件隐藏字段表示文件是否为隐藏的字段（布尔值）。默认值为空。Uri 字段表示指定包含 Uri 的字段。默认值为空。Root Uri 字段表示指定仅包含 Uri 的根部分的字段。默认值为空。 设置好字段参数后，单击【预览记录】按钮，弹出【预览数据数量】对话框，要预览的行数采用默认值，并单击【确定】按钮。 弹出【预览数据】对话框，展示 Excel 输入的数据，如图所示。 十、Kettle 生成记录 10.1、任务描述 在数据统计中，往往要生成固定行数和列数的记录，用于存放统计总数。 为方便记录 1-12 月份商品的销售总额，需要通过生成记录，生成一个月销售总额的数据表，包括商品名称和销售总额两个字段，记录销售的商品和当月商品统计销售总额，共生成 12 条记录。 10.2、实现思路 建立【生成记录】转换工程。 设置【生成记录】组件参数。 预览结果数据。 10.3、操作过程 1、建立【生成记录】转换工程 使用 ctrl+N 快捷键，创建【生成记录】转换工程，单击【核心对象】，展开【输入】对象，选中【生成记录】组件，并拖拽到右边工作区中，如图所示： 2、设置参数 双击【生成记录】组件，弹出创建【生成记录】对话框，如图所示： 该组件参数包含两种，分别是基础参数：步骤名称、限制、“Never stop generating rows” 和【字段】：名称、类型、格式、长度、精度、货币类型、小数、分组、值、设为空串？。 根据需要设置好相关参数后，生成 12 条记录的商品销售总额表，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值。 2）确定表的记录数。【限制】参数设置为 “12”。 3）设置字段参数。在【字段】表中，对个字段的参数进行设置，如图所示，此时完成【生成记录】组件参数的设置。 3、预览数据结果 单击【预览 (P)】按钮，弹出【输入预览记录数】对话框，预览记录数采用默认值，单击【确定】按钮。弹出【预览数据】对话框，展示生成记录的数据，如图所示： 十一、Kettle 生成随机数 11.1、任务描述 在工作中，往往需要生成随机数验证码，作为数据或文件的验证码。 为方便给授权用户验证文件，需要通过生成随机数，生成一组 MD5 信息授权码，作为数据文件的认证授权码。 11.2、实现思路 建立【生成随机数】转换工程 设置【生成随机数】组件参数 预览结果参数 11.3、操作过程 1、简历生成随机数转换工程 使用 ctrl+N 快捷键，创建【生成随机数】转换工程，单击【核心对象】，展开【输入】对象，选中【生成随机数】组件，并拖拽到右边工作区中，如图所示： 2、设置参数 双击【生成随机数】组件，弹出【生成随机值】对话框，如图所示： 【生成随机数】组件的参数，包含组件的基础参数和【字段】表参数。 在【生成随机值】对话框中，设置参数，随机生成一组 MD5 信息授权码，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值 “生成随机值”。 2）设置字段参数。在【字段】表中第 1 行，设置字段名称和类型。 ①点击【名称】参数输入框，键盘键入 “授权码”。 ②单击【类型】参数输入框，弹出【选择数据类型】对话框，选择【Random Message Authentication Code(HmacMD5)】类型，如图所示。 3、预览结果数据 在【生成随机数】转换工程中，单击【生成随机数】组件，再从工作区上方调出【转换调试窗口】对话框，展示生成随机数的数据，如图所示。 单击【快速启动】按钮，弹出【预览数据】对话框，展示生成随机数的授权码数据，如图所示。 十二、Kettle 获取系统信息 12.1、相关概念 系统信息是指 Kettle 系统环境的信息，包括了计算机系统的日期、星期等时间类型信息，计算机名称、IP 地址等设备信息，Kettle 系统转换过程中的信息等。 为方便读取计算机上到本月最后一天的交易数据文件，需要通过获取系统信息，获得当月最后一天的时间以及当前计算机名称与 IP 地址等系统信息。 12.2、实现思路 建立【获取系统信息】转换工程。 设置【获取系统信息】组件参数。 预览结果数据。 12.3、操作过程 1）建立获取系统信息转换工程 使用 Ctrl+N 快捷键，创建【获取系统信息】转换工程，单击【核心对象】选项卡，展开【输入】对象，选中【获取系统信息】组件，并拖拽到右边工作区中，如图所示： 2）设置参数 双击【获取系统信息】组件，弹出【获取系统信息】对话框，如图所示： 【获取系统信息】组件的参数包含组件的基础参数，以及【字段】表参数。 在【获取系统信息】对话框中，设置参数，获取当月最后一天的时间，以及当前的计算机名称与 IP 地址等系统信息，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值。 2）设置字段参数。在【字段】表中，设置字段参数。 ①设置第 1 行参数。【名称】参数设置为 “当月最后一天”。单击【类型】输入框，弹出【选择信息类型】对话框。选择“本月最后一天的 23::59:59” 类型，如图所示，并单击【确定】按钮。 ②设置第 2 行参数。与设置第 1 行参数类似，第 2 行参数的【名称】参数设置为 “计算机名称”，【类型】参数设置为 “主机名”。 ③设置第 3 行参数。与设置第 1 行参数类似，第 3 行参数的【名称】参数设置为 “IP 地址”，【类型】参数设置为 “IP 地址”，如图所示，此时已完成【获取系统信息】组件的参数设置。 3）预览结果数据 单击【浏览记录】按钮，弹出【Enter preview size】对话框，预览记录数采用默认值，单击【确定】按钮。弹出【预览数据】对话框，展示获取系统信息的数据，如图所示。 十三、Kettle 排序记录 13.1、任务描述 排序是对数据中的无序记录，按照自然或客观规律，根据关键字段大小递增或递减的次序，对记录重新排列的过程。 为了得出学生的成绩排名，需要对 “2019 年 11 月月考数学成绩. xls” 文件，使用【排序记录】组件，对学生的成绩从低到高排序。 13.2、实现思路 建立【排序记录】转换工程。 设置【排序记录】组件参数。 预览结果数据。 13.3、操作过程 1）建立排序记录转换工程 使用 Ctrl+N 快捷键，创建【排序记录】转换工程，接着创建【Excel 输入】组件，设置参数，导入 ““2019 年 11 月月考数学成绩. xls” 文件，预览数据，如图所示，其中 “数学” 字段数据处于无序状态。 在【排序记录】转换工程中，单击【核心对象】选项卡，展开【转换】对象，选中【排序记录】组件，并拖拽至右边工作区中。由【Excel 输入】组件指向【排序记录】组件，建立节点连接，如图所示： 2）设置参数 双击【排序记录】组件，弹出【排序记录】对话框，如图所示： 【排序记录】组件的参数包含了组件的基础参数和【字段】表参数，有关参数的说明如表所示。其中，【字段】表参数是设置参与排序的字段参数，可以对多个字段设置参数。 在【排序目录】对话框中，设置参数，将 “数学” 字段的数据按照从低到高进行排序，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值 “排序记录”。 2）确定排序目录。【排序目录】参数保留默认值 “%%java.io.tmpdir%%”。 3）设置排序字段参数。在【字段】表中，对各字段的参数进行设置，此时完成【排序目录】组件参数的设置，如图所示： 3）预览结果数据 在【排序记录】排序工程中，单击【排序记录】组件，再点击预览数据，展示排序后的数据，如图所示： 十四、Kettle 去除重复记录 14.1、任务描述 由于输入或其他错误的原因，数据文件中可能出现两条或多条数据完全相同的记录，这些相同的记录成为重复记录。 重复的记录属于 “脏数据”，会造成数据统计和分析不正确，必须清洗掉重复记录。 由于在 “期考成绩. xls” 文件中，发现存在序号不同，但是学号、各科考试成绩完全相同的记录，所以需要使用【去除重复记录】组件，去除这些重复的数据。 14.2、实现思路 建立【去除重复记录】转换工程。 设置【去除重复记录】组件参数。 预览结果数据。 14.3、操作过程 1）建立去除重复记录转换工程 在去除重复记录（简称 “去重”）之前，必须使用关键字段对数据记录进行排序，确定哪些记录属于重复记录。 使用 Ctrl+N 快捷键，创建【去除重复记录】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “期考成绩. xls” 文件。 接着创建【排序记录】组件，并由【Excel 输入】组件指向【排序记录】组件，简历节点连接，如图所示： 双击【排序记录】组件，对 “学号” 字段按照升序进行排序后预览数据，如图所示，除了 “序号” 字段数据外，“学号”分贝为 “201709023”“201709028” 的数据各有两条记录，并且对应的 “语文”“数学” 等考试科目和 “创建时间” 的数据也相同。 在【去除重复记录】转换工程中，单击【核心对象】选项卡，展开【转换】对象，选中【去除重复记录】组件，并拖拽至右边工作区中，并由【排序记录】组件指向【去除重复记录】组件，建立节点连接，如图所示： 2）设置参数 双击【去除重复记录】组件，弹出【去除重复记录】对话框，如图所示： 【去除重复记录】组件的参数包含了组件的基础参数和【用来比较的字段】表参数。 在【去除重复记录】对话框中，设置参数，去除学号相同的记录，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值 “去除重复记录”。 2）确定计数器字段。【增加计数器到输出】设置为 “√”，【计数器字段】设置为 “重复行数”。 3）确定错误描述。【重定向重复记录】设置为 “√”，【错误描述】设置为 “重复输入”。 4）设置用来比较字段参数，在【用来比较的字段】表中，【字段名称】设置为 “学号”，【忽略大小写】设置为 “N”，此时完成【去除重复记录】组件参数的设置，如图所示。 3）预览结果数据 在【去除重复记录】转换工程中，单击【去除重复记录】组件，点击预览去除重复记录后的数据，如图所示： 十五、Kettle 替换 NULL 值 15.1、任务描述 在 Kettle 转换过程中，默认情况下，会将控制当做 NULL 值处理。如果数据类型字段出现 NULL 值，那么在计算时就会出现错误。 在 “2019 年 11 月月考英语成绩. xls” 文件中，学号为 “201709007” 的同学没有参加考试，根据规定高考时分数将按零分处理，需要使用【替换 NULL 值】组件，使用 “0” 替换该同学的英语考试分数。 15.2、实现思路 1）建立【替换 NULL 值】转换工程。 2）设置【替换 NULL】组件参数 3）预览结果数据。 15.3、操作过程 1）建立替换 NULL 值转换工程 使用 Ctrl+N 快捷键，创建【替换 NULL 值】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “2019 年 11 月月考英语成绩. xls” 文件，预览数据，“学号”字段数据为 “201709007” 所对应的 “英语” 字段数据为 “” 即（NULL），如图所示： 在【替换 NULL 值】转换工程中，单击【核心对象】选项卡，展开【应用】对象，选中【替换 NULL 值】组件，并拖拽至右边工作区中。由【Excel 输入】组件指向【替换 NULL 值】组件，建立节点连接，如图所示： 2）设置参数 双击【替换 NULL 值】组件，弹出【替换 NULL 值】对话框，如图所示： 【替换 NULL 值】组件的参数包含了组件的基础参数和【替换所有字段的 null 值】【选择字段】【选择值类型】3 种方式设置的参数，每种方式有多个不同的参数，有关参数的说明如表所示。 基础参数名称说明作业名称表示【替换 NULL 值】组件名称，在单个转换工程中，名称必须唯一，默认值是【替换 NULL 值】组件名称。选择字段表示对所有记录的、指定字段的 NULL 值进行值替换的方式。默认值为空。选择值类型表示对所有记录、指定的数据类型的 NULL 值进行替换的方式。默认值为空。 下图这 3 种方式只能三选一，默认是【替换所有字段的 null 值】方式，勾选【选择字段】参数后，通过【字段】表设置具体参数；勾选【选择值类型】参数后，通过【值类型】表设置具体参数。 参数名称说明替换所有字段的 NULL 值表示对所有记录、所有字段的 NULL 值进行替换方式，默认的替换方式。具体如下：1）值替换为：表示用来替换 NULL 的值，默认值为空。2）设置空字符串：表示是否设置空字符串，默认值为空。3）掩码（日期）：表示日期字段的掩码格式，默认值为空。字段表示勾选【选择字段】参数后，使用【字段】表设置参数，具体如下：1）字段：表示输入流的字段名称，单击下拉框选择设置。2）值替换为：表示要替换 NULL 的值。3）转换掩码（日期）：表示日期字段的掩码格式，默认值为空。4）设置空字符串：表示是否设置空字符串，选项有：是、否，默认值为空。值类型表示勾选【选择值类型】参数后，使用【值类型】表设置参数，具体如下：1）字段：表示输入流的字段名称，单击下拉框选择设置。2）值替换为：表示要替换 NULL 的值。3）转换掩码（日期）：表示日期字段的掩码格式，默认值为空。4）设置空字符串：表示是否设置空字符串，选项有：是、否，默认值为空。 在【替换 NULL 值】对话框中，设置参数，用 “0” 替换 “英语” 字段的数据“null”，步骤如下： 1）确定组件名称。【步骤名称】参数保留默认值 “替换 NULL 值”。 2）选择【选择字段】方式设置字段参数。【选择字段】设置为 “√”，并在【字段】表中，对字段的参数进行设置。此时完成【替换 NULL 值】组件参数的设置，如图所示。 3）预览结果数据 在【替换 NULL 值】转换工程中，单击【替换 NULL 值】组件，预览替换 NULL 值后的数据，如图所示： 十六、Kettle 过滤记录 16.1、任务描述 在数据处理时，往往要对数据所述类别、区域和时间等进行限制，将限制范围外的数据过滤掉。 为了统计 2 班的考试人数和成绩，需要对 “2019 年 10 月年级月考数学成绩. xls” 文件，使用【过滤记录】组件，过滤掉不是 2 班的数据。 16.2、实现思路 建立【过滤记录】转换工程。 设置【过滤记录】组件参数。 预览结果数据。 16.3、操作过程 1）建立过滤记录转换工程 使用 Ctrl+N 快捷键，创建【过滤记录】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “2019 年 10 月年级月考数学成绩. xls” 文件，预览数据，如图所示，文件包括有 1 班、2 班的数据。 在【过滤记录】转换工程中，单击【核心对象】选项卡，展开【流程】对象，选中【过滤记录】组件，并拖拽至右边工作区中。由【Excel 输入】组件指向【过滤记录】组件，建立节点连接，如图所示： 2）设置参数 双击【过滤记录】组件，弹出【过滤记录】对话框，如图所示： 【过滤记录】组件的参数包含组件的基础参数和【条件】表达式参数，有关参数的说明如表所示。 参数名称说明基础参数步骤名称表示【过滤记录】组件名称，在单个转换工程中，名称必须唯一，默认值为【过滤记录】组件名称。发送 true 数据给步骤表示当条件为 true 时，记录被发送到此组件（步骤）。此参数也可以在与下一个组件（步骤）进行节点连接是设置，默认值为空。发送 false 数据给步骤表示当条件为 false 时，记录被发送到此组件（步骤）。此参数也可以在与下一个组件（步骤）进行节点连接是设置，默认值为空。条件表示过滤条件的表达式，在【条件】表达式输入框中设置表达式中各个参数默认值为空。 条件表达式是由条件函数（运算符）构成的一个赋值语句，格式为：&lt;字段&gt;&lt; 条件函数 &gt;&lt; 表达式 &gt;，格式的中间为比较函数，左边为字段，右边是值表达式，如 a=5、a&gt;(b+2)、a&lt;=10 等。为了方便读者理解，在【条件】表达式输入框中，增加了条件表达式设置的指向说明，如图所示： 1）增加子条件 单击 + 图表可以增加子条件，这时在【条件】表达式输入框中，显示出增加的条件表达式，初次生成的是一条 “null=[]” 的空表达式，如图所示： 单击 “null=[]” 空表达式，可对该表达式进行设置，如图所示，点击 “向上” 按钮可以向上切换回条件表达式。 右键单击子条件表达式，弹出右键快捷菜单，可以对子条件进行编辑、删除、复制、粘贴、移动位置等操作，如图所示： 2）选择输入流的字段 单击 “选择输入流字段” 指向的【】字段输入框，弹出【字段】对话框，列出输入流字段表，选择需要过滤的字段，选中 “班级” 字段，如图所示，单击下方【确定】按钮，确定输入流字段。 3）选择比较函数 单击 “比较函数” 指向的【=】函数输入框，弹出【函数】对话框，并列出过滤比较函数，有关过滤比较函数的说明如表所示（部分）： 函数名称说明REGEXP表示正则表达式，判断表达式字段是否与模式匹配。IN NULL表示为空，判断表达式字段是否为空。IS NOT NULL表示不为空，判断表达式字段是否不为空。IN LIST表示在列表中，判断表达式字段是否在指定的 list 列表中。CONTAINS表示包含，判断表达式字段是否包含右边的值。STARTS WITH表示以什么开始，判断表达式字段是否以右边的值开始。ENDS WITH表示以什么结束，判断表达式字段是否以右边的值结束。LIKE表示包括，判断表达式字段是否包括右边的值。TRUE表示真，判断表达式字段是否为真。 选择 “=” 的过滤比较函数，单击【确定】，确认过滤比较函数。 4）输入比较的值 单击 “输入要比较的值” 指向的【】值输入框，弹出【E 输入一个值】对话框，输入比较的值。 有关【E 输入一个值】对话框中的参数的说明如表所示。需要注意，若设置 “输入要比较的值” 指向的【】值参数，则不能设置 “选择要比较的字段” 指向的【】字段参数，二者只能选其一。 参数名称说明类型表示值的类型。类型选项有：BigNumber、Binary、Boolean、Date、Integer、Internet、Address、Number、String、Timestamp。默认值为 String。值表示值，可以是具体值或表达式，默认值为 1.转换格式表示值的转换格式，默认值为空。长度表示值的长度，默认值为 - 1。精度表示值的精度，默认值为 - 1。 5）选择比较字段 单击 “选择要比较的字段” 指向的【】字段输入框，弹出类似的【字段】对话框，选中要比较的字段，单击确定按钮，确定要比较的字段。同样，若设置了 “选择要比较的字段” 指向的【】字段参数，则不能设置 “输入要比较的值” 指向的【】值参数，二者只能选其一。 6）条件取反 鼠标移向 “条件取反” 指向的输入框，显示出黑底红字的“NOT”，单击该输入框并移开鼠标，此时显示白底黑字的“NOT”，表示条件取反，即若表达式为 true，则条件为 false。 若表达式为 false，则条件 true。“条件取反” 指向的输入框为一个奇偶输入框，单击取反，再次单击则取正。 在导入的 “2019 年 10 月年级月考数学成绩. xls” 文件中，过滤掉不是 2 班的数据，对条件表达式按照下表的设置。 输入流【&lt;filed&gt;】字段【=】比较函数【&lt;Value&gt;】输入一个值班级=单击【&lt;field&gt;】输入框，弹出【E 输入一个值】对话框，对参数进行设置，如下图所示。 此时完成【过滤记录】组件参数的设置，如图所示： 3）预览结果数据 在【过滤记录】转换工程中，单击【过滤记录】组件，预览过滤记录后的数据，如图所示： 十七、Kettle 值映射 17.1、任务描述 在数据处理系统中，为了加快处理速度、减少内存和存储空间消耗，往往使用数字、字母，或他们的组合表示真实的数据含义，例如，用 “1” 和“0”分别表示性别，难以直接看懂。 在某校学生的 “学籍信息. xls” 文件中，性别字段数据分别用 “1” 和“0”表示。为了更加直观、一目了然地读懂学生的学籍信息，需要使用【值映射】组件，还原其对应的值 “男” 或“女”。 kettle 值映射能够解决这一需求。 17.2、实现思路 建立【值映射】转换工程。 设置【值映射】组件参数。 预览结果数据。 17.3、操作过程 1）建立值映射转换工程 使用 Ctrl+N 快捷键，创建【值映射】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “学籍信息. xls” 文件，预览数据，如图所示。 当前数据中，“性别”字段的数据，以 “0” 或“1”表示； “学籍”字段的数据，以 “H” 或“J”表示； “籍贯” 字段有一些数据前面有空格。 在【值映射】转换工程中，单击【核心对象】选项卡，展开【转换】对象，选中【值映射】组件，并拖拽至右边工作区中。由【Excel 输入】组件指向【值映射】组件，建立节点连接，如图所示。 2）设置参数 双击【值映射】组件，弹出【值映射】对话框，如图所示。 将 “性别” 字段中 “1”“0” 数据分别用 “男”“女” 映射替换，对参数进行设置。此时完成【值映射】组件参数的设置，如图所示。 3）预览结果数据 在【值映射】转换工程中，单击【值映射】组件，预览进行值映射操作后的数据，如图所示。 十八、Kettle 字符串替换 18.1、任务描述 字符串替换与值映射非常类似，不同之处在于字符串替换的字段值是字符串，值映射的字段可以是多种数据类型。 由于在 “学籍信息. xls” 文件中，学籍数据用 “H” 或“J”表示，需要使用【字符串替换】组件，分别还原其对应的值 “户籍生” 和“借读生”。 18.2、实现思路 建立【字符串替换】转换工程。 设置【字符串替换】组件参数。 预览结果数据。 18.3、操作过程 1）建立字符串替换转换工程 使用 Ctrl+N 快捷键，创建【字符串替换】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “学籍信息. xls” 文件。 在【字符串替换】转换工程中，单击【核心对象】选项卡，展开【转换】对象，选中【字符串替换】组件，并拖拽至右边工作区中。由【Excle 输入】组件指向【字符串替换】组件，建立节点连接，如图所示。 2）设置参数 双击【字符串替换】组件，弹出【字符串替换】对话框，如图所示。 【字符串替换】组件的参数包含组件的基础参数和【字段】表参数，有关参数说明如表所示。 参数名称说明基础参数步骤名称表示【字符串替换组件名称】，在单个转换工程中，名称必须唯一。默认值是【字符串替换】组件名称。字段表示对将要进行字符串替换的字段参数，使用一个【字段】表对字段参数进行设置，有关参数说明如下所示。输入流字段表示要进行字符串替换的输入流字段。默认值为空。输出流字段表示进行字符串替换后的输出流字段，为空时覆盖原来要进行替换的输入流字段，默认值为空。使用正则表达式表示是否使用正则表达式，选项有：Y、N。默认值为空。搜索表示是否搜索此次字符串的匹配值，默认值为空。使用… 替换表示要替换匹配值的字符串数据，默认值为空。设置为空串?表示是否设置空字符串，选项有：Y、N。默认值为空。使用字段值替换表示使用一个字段值替换字符串，默认值为空。整个单词匹配表示是否要整个单词都匹配，选项有：Y、N，默认值为空。大小写敏感表示是否区分大小写，选项有：Y、N，默认值为空。In Unicode表示是否设置 Unicode，选项有：Y、N，默认值为空。 在【字符串替换】对话框中，设置参数，对输入数据中 “学籍” 字段中数据 “H” 和“J”，分别使用 “户籍生” 和“借读生”进行替换，步骤如下： 1）确认组件名称。【步骤名称】保留默认值，设置为 “字符串替换”。 2）确定字段参数。对【字段】表的参数进行设置。此时完成【字符串替换】组件参数的设置，如图所示。 3）预览结果数据 在【字符串替换】转换工程中，单击【字符串替换】组件，预览字符串替换后的数据，如图所示。 十九、Kettle 字符串操作 19.1、任务描述 在数据输入过程中，有时候不小心输入的多余的空格、错误的字符等，字符串操作是指将数据中不需要的字符处理掉，Kettle 字符串操作可以解决这一需求。 由于在 “学籍信息. xls” 文件中，学生学籍信息的籍贯字段数据前后有多余的空格，需要使用【字符串操作】，去除这些空格，规范学籍信息。 19.2、实现思路 建立【字符串操作】转换工程。 设置【字符串操作】组件参数。 预览结果数据。 19.3、操作过程 1）建立字符串操作转换工程 使用 Ctrl+N 快捷键，创建【字符串操作】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “学籍信息. xls” 文件。 在【字符串操作】转换工程中，单击【核心对象】选项卡，展开【转换】对象，选中【字符操作】组件，并拖拽至右边工作区中。由【Excel 输入】组件指向【字符串操作】组件，建立节点连接，如图所示。 2）设置参数 双击【字符串操作】组件，弹出【String operations】对话框，如图所示。 【字符串操作】组件的参数包含组件的基础参数和【The fields to process】表字段参数，有关参数的说明如表所示。 在【String operations】对话框中，设置参数，删除 “籍贯” 字段数据中的空格，步骤如下： 1）确定组件名称。【Step name】参数保留默认值 “字符串操作”。 2）设置字符串操作的字段参数。在【The fields to process】表中设置字段参数，在表第 1 行，单击【In steam field】输入框，在输入流字段中选中 “籍贯” 字段，单击【Trim type】输入框，在选项中选中“both”，其他参数使用默认值。此时完成【字符串操作】组件参数的设置，如图所示。 3）预览结果数据 在【字符串操作】转换工程中，单击【字符串操作】组件，预览进行字符串操作后的数据，如图所示。 二十、Kettle 分组 20.1、任务描述 在进行数据统计中，往往要对类别、区域、型号等范围进行统计，分组是对指定的字段或字段集合的数据进行分组统计，Kettle 分组组件可以解决这一需求。 为了了解各班级和学生的学业情况，需要对 “2019 年 10 月月考英语成绩. xls” 文件，使用【分组】组件，统计各班的人数和平均分数。 20.2、实现思路 建立【分组】转换工程。 设置【分组】组件参数。 预览结果数据。 20.3、操作过程 1）建立分组转换工程 在分组之前，必须使用关键字段对数据记录进行排序，确定哪些记录分组在一起。参考 Kettle 排序记录的操作过程，建立排序并浏览 “2019 年 10 月月考英语成绩. xls” 文件数据。 使用 Ctrl+N 快捷键，创建【分组】转换工程。接着创建【Excel 输入】组件，设置参数，导入 “2019 年 10 月月考英语成绩. xls” 文件。 再创建【排序记录】组件，并由【Excel 输入】组件指向【排序记录】组件，建立节点连接，如图所示。 双击【排序记录】组件，设置 “班级” 字段参数，按照生序排序，预览排序记录数据，如图所示，“1 班”和 “2 班” 分别被排序在一起。 在【分组】转换工程中，单击【核心对象】选项卡，展开【统计】对象，找到【分组】组件，并拖拽到右边工作区中，并由【排序记录】组件指向【分组】组件，建立节点连接，如图所示。 2）设置参数 双击【分组】组件，弹出【分组】对话框，如图所示。 【分组】组件参数包含组件的基础参数，以及【构成分组的字段】和【聚合】字段参数，参数说明如表所示。 参数名称说明基础参数步骤名称表示分组的组件名称，在单个转换工程中，名称必须唯一。默认值是【分组】的组件名称。包括所有的行表示是否包括所有记录。使用勾选框设置参数，希望在输出中包含所有记录，则勾选，只想输出聚合记录，则不勾选。默认值为空。排序目录表示指定存储临时文件的目录。分组的记录数超过 5000 个时，必须指定搞一个目录。此参数只有勾选【包括所有的行】参数后才能设置，默认值是系统的标准临时目录 %%java.io.tmpdir%%。临时文件前缀表示命名临时文件的文件前缀，只有勾选【包括所有的行】参数后才能设置。默认值为 grp。添加行号，在每个组中重新启动表示是否添加一个记录号，在每个组中从 1 重新启动。勾选此参数时所有记录都包含在输出中，且每个记录都有一个记录号。此参数在勾选【包括所有的行】参数后才有效。默认值为空。行号列名表示要为每个新组添加记录的字段名称。默认值为空。总返回一个结果行表示是否即使没有输入记录，也返回结果记录。当没有输入记录时，返回计数为 0。如果只想有输入时才输出结果记录，则此参数不勾选。默认值为空。构成分组的字段表示分组的字段参数。分组的字段可以有多个，使用一个【构成分组的字段】表设置【分组字段】参数，可以设置多个分组子段。需要注意的是，如果没有分组的字段，那么该表留空来计算整个数据集的聚合函数。默认值为空。聚合表示聚合字段的参数，使用一个【聚合】表来设置聚合字段名称、聚合方法和输出结果新字段名称，有关聚合字段的参数说明如下内容所示。名称表示聚合字段的名称，输出结果的新字段名称，默认值为空。Subject表示对其使用聚合方法的对象字段，默认值为空。类型表示聚合方法。在下拉框中选取聚合方法，默认值为空。值表示聚合的值，默认值为空。 在【分组】对话框中，设置参数，分组统计各班的人数和平均分数，步骤如下： 1）设置组件名称。【步骤名称】参数采用默认值 “分组”。 2）确定分组字段。在【构成分组字段】表的第 1 行，【分组字段】设置为 “班级”。 3）确定聚合字段并设置参数。对【聚合】表的参数进行设置。此时完成【分组】组件参数的设置，如图所示。 3）预览结果数据 在【分组】转换工程中，单击【分组】组件，预览数据分组后的结果，如图所示。 二十一、Kettle 多线程数据优化 这篇文章重点介绍多线程使用同步的配置思想，希望对大家有所帮助。 21.1、 表输出的多线程实例。 步骤的多线程执行方法是通过设置步骤的 “更改开始复制数量” 属性来实现。如果是表格输出控件，选择”ChangeNunberofCopiestoStart..”，然后在 Numberofcopies 的输入框中填入并发的线程数量。 单向程测试：数据量 10W，单线程 14 分钟。 多线程测试：3 线程 7 分钟的运行，效率加倍。“TableOutput 这一步同时执行了 3 个线程，而 TableInput 则以轮询的方式将数据流按行发送到 3 个 “表输出” 线程。 通过以上示例，您可以清楚地看到多线程相对于单线程而言效率的提升。 但是，在多线程”insert/update” 场景中，如果更新的 key 并非惟一，则有可能产生死锁 (多个线程一次更新同一行的数据) 通过以上示例，您可以清楚地看到多线程相对于单线程而言效率的提升。 但是，在多线程”insert/update” 场景中，如果更新的 key 并非惟一，则有可能产生死锁 (多个线程一次更新同一行的数据) 21.2、 ODS 概要 是完全提取还是递增式提取，同步化使用？ 配置的示例： 其中一种是增量式的增量条件，另一种是完全抽取，不需要抽取条件。 21.3、 实施步骤 1、从组态表中读取待提取的资料表。 2、job_ods_all_exe 同时执行 10 个线程，收到前一步传递的表名. 数据库名称. 提取类型等参数。 3、job_ods_all_exe，是否按 ETL_TYPE 分发数据是递增式提取还是完全抽取。 4、全量 ODS 和递增 ODS 实现逻辑： 二步是通过 “表输入” 步骤查询数据，全量是直接将表 truncate 为 truncate，然后插入数据；deltaODS 是使用插入更新的方式。 有两个必须插入一个更新控件：key. 更新的字段，key 可以将字段以传参的形式传递，需要扩展 etl_ods_table 表字段，配置源表的 key，通常配置三个 key 字段就足够了；kettle 自带的 “insert/update” 控件的 update 域是必选项，这是无法做到通用的，因为不可能所有同步表字段都是相同的，这需要定制插件，将 updatefield 变成必需项： 21.4、 其他配置项目 1、目标表配置：为 etl_ods_table 表中为每一个同步表配置一个目标表，用一个变量来表示目标表用：tagetdbschema.{taget_db_schema}.tagetd​bs​chema.{taget_table_name}，因此，可重复使用组件，提高总体灵活性。 2、资料库连结：设定源表与目标资料表使用资料表连结，以参数化方式，以资料库连结方式，设定资料表结构： 并且为 etl_ods_table 配置一个表，源表和目标表的数据量。据库连接的 ID，查询同步表的信息时，数据库连接的也同时通过参数传递。 二十二、Kettle windows 定时调度作业 本教程使用的 kettle 版本是 7.0，调度之前务必先执行验证作业或转换是可以成功执行的。 22.1、 编写 kettle.bat 脚本 （kitchen.bat 后面可以是 - 也可以是 / 然后再加 options，而 options 后面可以是 = 也可以是: 也可以是空格） D:cd D:\\kettle\\pdi-ce-7.1.0.0-12\\data-integration kitchen.bat -rep=product -user=admin -pass=admin -dir=/ -job = 人才生产线 job -level=basic&gt;D:\\kettle\\JOB.log 顺便解释一下： 1、首先 cd 是进入到 kettle 安装执行文件目录下 -rep 表示仓库名，也就是你的资源库的名称，我的资源库名称就是 product -user 资源库用户名 这里就是 admin -pass 资源库密码 默认是 admin ，为了安全我们可以更改密码 -dir 就是你的 job 在资源库中存放目录 支持中文的目录 -job job 的名称 这里我的 job 名称就是：人才生产线 job（job 名字不要带后缀，不然提示找不到 job 错误） -level 日志的级别 我们普通的写 basic 就可以了，就是最基本的 最后面就是日志了，针对 job 跑起来的相关信息都会保存在 job.log 中 2、针对相关的更多参数如下（options）： /rep : Repository name /user : Repository username /pass : Repository password /job : The name of the job to launch /dir : The directory (dont forget the leading /) /file : The filename (Job XML) to launch /level : The logging level (Basic, Detailed, Debug, Rowlevel, Error, Nothing) /logfile : The logging file to write to /listdir : List the directories in the repository /listjobs : List the jobs in the specified directory /listrep : List the available repositories /norep : Do not log into the repository /version : show the version, revision and build date /param : Set a named parameter =. For example -param:FOO=bar /listparam : List information concerning the defined parameters in the specified job. /export : Exports all linked resources of the specified job. The argument is the name of a ZIP file. 注意： 保存 kitchen.bat 文件时，刚开始选的编码是 utf8，此时中文乱码（后改为 Unicode 也是乱码），最后改为 ANSI 就可以了。 22.2、 cmd 测试 bat 脚本 完成 bat 脚本以后，双击测试一下，会跳出 cmd 命令窗口，此时打开 JOB.log 日志记录，会发现已经在执行作业了，等待完成以后，cmd 窗口会自动关闭。接下来就是 Windows 的定时任务来管理调度 bat 脚本了。 22.3、 windows 下建立执行任务 （我的服务器是 Windows Server 2016 Datacenter） 打开控制面板–管理工具–任务计划程序 打开右侧的创建基本任务，填写作业名称，然后下一步打开触发器： 打开触发器，根据自己的需求选择执行频率，然后下一步打开具体的设置： 打开操作，下一步打开具体设置（选择需要执行的 bat 脚本），下一步完成： 至此，Windows 计划任务调度 kettle 作业完成。 二十三、Kettle 增量同步 增量同步的总体思路是：首先，获取此表的增量数据。 如何获得增量？源表需要一个时间字段来代表该记录的最新更新时间（只要该记录发生变化，时间字段就会更新）。 当然，最好有一个时间字段。如果没有，您可能需要进行全表比较等操作；通常，业务系统的表中有主键。在我们获得增量数据后，我们需要判断记录的新插入或更新记录。 如果是更新记录，我们需要先将数据加载到中间表，然后根据主键删除目标表中现有的数据，最后将此增量数据插入目标表。 本教程简单介绍了如何通过 kettle 实现简单的数据增量同步。 job 如下： 如下转换：获取区服列表，将 id 列表保存到结果（内存） job: 同构数据库单表抽取（每个输入执行一次） 同构数据库单表抽取（job） 的具体实现如下： 转换：获取数据库连接 ID 从结果获取本次输入 id，并设置为变量 parmid 转换：获取数据库连接信息 转换：获取最大时间 获取目标的最大时间并设置变量 获取源表最大时间并设置变量，注（源数据库连接 dblink 为动态连接） dblink： 转换：删除目标表最后时间点的数据（防止同一秒中出现多条记录，漏数据） 转换：抽取数据 转换：写入 ETL 日志 ","link":"https://pandajackpragrammer.github.io/post/etl-kettle/"},{"title":"加密鸽cryptgeon---阅后即焚加密分享工具","content":" 介绍 cryptgeon 是一个安全的、开源的共享笔记或文件服务，其灵感来源于 PrivNote。 1. 介绍 cryptgeon 是一个安全的、开源的共享笔记或文件服务，其灵感来源于 PrivNote。 后台是用 Rust 写的，前台是用 Svelte 和 Typecript。 GitHub 开源项目，支持 Docker 搭建。 1.1 特点 咕咕这边简单在网上也抄~~~ 搜集~了一些特点，供大家参考（翻译自 GitHub 的 README）： GitHub 完全开源，可以免费使用 Docker 搭建，10 分钟搞定 在浏览器中加密，服务器端无法解密内容 可以设置浏览次数或指定分享时间，超出次数（最大可设置100次）或者时间后（最长可设置360分钟），文件永久消失（服务器所有者也无法看到） 文件存在内存中，没有持久性 支持黑暗模式 1.2 工作原理 每个笔记都会生成一个的 ID（256 位）和密钥 256（位）。这个 ID 用于保存和检索笔记。 然后，在客户端用密钥以 GCM 模式对笔记进行 AES 加密，之后后发送到服务器。 数据只存储在内存中，不会持久化到硬盘上（意味着重启数据会丢失）。 2. 项目展示 GitHub 原项目地址：https://github.com/cupcakearmy/cryptgeon（205 star） Demo 地址：https://cryptgeon.nicco.io 官方 Docker 地址：https://hub.docker.com/r/cupcakearmy/cryptgeon 直接丢几个图片： 3. 搭建环境 系统：Debian 10（DD 脚本 非必需 DD 用原来的系统也 OK） 域名一枚，并做好解析到服务器上（域名购买、域名解析 视频教程） 安装好 Docker、Docker-compose（相关脚本） 【非必需】提前安装好宝塔面板海外版本 aapanel，并安装好 Nginx（安装地址） 【非必需本教程采用】安装好 Nginx Proxy Manager（相关教程） 4. 搭建视频 YouTube：https://youtu.be/SrXThpfc4ow 哔哩哔哩【高清版本可以点击去吐槽到 B 站观看】： 5. 搭建方式 5.1 搭建 服务器初始设置，参考 sudo -i # 切换到root用户 apt update -y # 升级packages apt install wget curl sudo vim git # Debian系统比较干净，安装常用的软件 创建一下安装的目录： mkdir -p /root/data/docker_data/cryptgeon cd /root/data/docker_data/cryptgeon nano docker-compose.yml docker-compose.yml填入以下内容： # docker-compose.yml version: '3.8' services: redis: image: redis:7-alpine app: image: cupcakearmy/cryptgeon:latest depends_on: - redis environment: SIZE_LIMIT: 4 MiB ports: - 8080:8000 下面是旧版的，留言区读者反馈无法创建加密内容，建议用上面新版 yaml 文件，后续大家发现搭建有问题，可以去看看文末的 GitHub 原仓库信息。 version: '3.7' services: memcached: image: memcached:1-alpine entrypoint: memcached -m 256M -I 8M # Limit to 128 MB Ram, 4M per entry, customize at free will. （限制最大使用128M的内存，每条项目最大使用4M内存，可以自己修改） app: image: cupcakearmy/cryptgeon:latest depends_on: - memcached environment: SIZE_LIMIT: 8M # 这边的4M要与上面对应 ports: - 8080:5000 # 冒号左边的端口8080可以改成任意你没有用过的端口 注意：VPS 的内存最好大于 1G，可以再设置 1G 的 SWAP，本项目内容存储在内存中～ 设置 SWAP 可以用脚本: wget -O box.sh https://raw.githubusercontent.com/BlueSkyXN/SKY-BOX/main/box.sh &amp;&amp; chmod +x box.sh &amp;&amp; clear &amp;&amp; ./box.sh 没问题的话，ctrl+x退出，按y保存，enter确认。 查看端口是否被占用，输入： lsof -i:8080 #查看8080端口是否被占用，如果被占用，重新自定义一个端口 如果出现： -bash: lsof: command not found 运行： apt install lsof #安装lsof 如果端口没有被占用，可以运行： docker-compose up -d 访问：http:服务ip:8080 即可。 注意： 1、不知道服务器 IP，可以直接在命令行输入：curl ip.sb，会显示当前服务器的 IP。 2、遇到访问不了的情况，请在宝塔面板的防火墙和服务商的后台防火墙里打开对应端口。 5.2 更新 cd /root/data/docker_data/cryptgeon # 进入docker-compose所在的文件夹 docker-compose pull # 拉取最新的镜像 docker-compose up -d # 重新更新当前镜像 利用 Docker-compose 搭建的应用，更新非常容易～ 5.3 卸载 sudo -i cd /root/data/docker_data/cryptgeon # 进入docker-compose所在的文件夹 docker-compose down # 停止容器，此时不会删除映射到本地的数据 cd ~ rm -rf /root/data/docker_data/cryptgeon # 完全删除映射到本地的数据 利用 Docker-compose 搭建的应用，删除也非常容易～ 6. 反向代理（必须） 此项目和别的项目不同，必须采用 https 形式，否则浏览器无法加密，无法使用。 6.1 利用 Nginx Proxy Manager 在添加反向代理之前，确保你已经完成了域名解析 之后，登陆 Nginx Proxy Manager（不会的看这个：安装 Nginx Proxy Manager（相关教程）） 注意： Nginx Proxy Manager（以下简称 NPM）会用到80、443端口，所以本机不能占用（比如原来就有 Nginx） 直接丢几张图： 注意填写对应的域名、IP和端口，按文章来的话，应该是8080 IP 填写： 如果 Nginx Proxy Manager 和 cryptgeon 在同一台服务器上，可以在终端输入： ip addr show docker0 查看对应的 Docker 容器内部 IP。 否则直接填cryptgeon所在的服务器IP就行 再次打开，勾选这些： 然后就可以用域名来安装访问了。 7. 使用教程 见咕咕鸽的视频 8. 结尾 祝大家用得开心，有问题可以去 GitHub 提 Issues，也可以在评论区互相交流探讨。 同时，有能力给项目做翻译的同学，也欢迎积极加入到项目中来，贡献自己的一份力量！ 9. 参考资料 GitHub 原项目地址：https://github.com/cupcakearmy/cryptgeon（205 star） Demo 地址：https://cryptgeon.nicco.io 官方 Docker 地址：https://hub.docker.com/r/cupcakearmy/cryptgeon ","link":"https://pandajackpragrammer.github.io/post/cryptgeon/"},{"title":"Enclosed--开源阅后即焚加密工具","content":" 唠嗑 今天和大家分享一个加密分享的小工具——enclosed，极简主义网页应用程序，旨在私密和安全地发送便条。 1. 唠嗑 今天和大家分享一个加密分享的小工具——enclosed，极简主义网页应用程序，旨在私密和安全地发送便条。 2. 介绍 非常简约，一目了然。 功能特点： 支持端到端加密：笔记在客户端使用 AES-GCM 进行加密，采用 PBKDF2 派生的 256 位密钥。 支持添加文件附件 服务器无法访问笔记或文件的内容。 可配置的安全选项：设置密码、过期时间，阅后即焚。 用户界面简单直观，便于快速共享笔记。 提供多种语言版本。 可选电子邮件 / 密码认证来创建笔记。 支持暗黑模式 响应式设计，从桌面电脑到手机均能正常工作。 开源，源代码根据 Apache 2.0 许可证发布. 支持 docker 一键部署 支持从终端创建笔记的命令行接口. 非常轻量 3. 相关地址 官方 GitHub 地址：https://github.com/CorentinTh/enclosed (目前 261 个 star，欢迎大家去给项目点星星！） Demo：https://enclosed.cc/ 文档：https://docs.enclosed.cc/ 4. 搭建环境 系统：Debian 11 （DD 脚本 非必需 DD，用原来的系统也 OK，之后教程都是用 Debian 或者 Ubuntu 搭建～） 安装好 Docker、Docker-compose（相关脚本） 【必需】域名一枚，并做好解析到服务器上（域名购买、域名解析 视频教程） 【非必需】提前安装好宝塔面板海外版本 aapanel，并安装好 Nginx（安装地址） 【非必需本教程选用】安装好 Nginx Proxy Manager（相关教程） 5. 搭建视频 5.1 YouTube 视频地址：https://youtu.be/bAn0gF1yz-g 5.2 哔哩哔哩 哔哩哔哩：https://www.bilibili.com/video/BV16AxUexExL/ 6. 搭建方式 6.1 安装 Docker 与 Nginx Proxy Manager 可以直接参考这篇内容： https://blog.laoda.de/archives/nginxproxymanager/ 6.2 创建安装目录 创建一下安装的目录： sudo -i mkdir -p /root/data/docker_data/enclosed cd /root/data/docker_data/enclosed 接着我们来编辑下docker-compose.yml vim docker-compose.yml services: enclosed: image: corentinth/enclosed ports: - 3000:8787 # 3000可以改成服务器上没有用过的端口 volumes: - ./enclosed-data:/app/.data restart: unless-stopped 同样，修改完成之后，可以在英文输入法下，按 i 修改，完成之后，按一下 esc，然后 :wq 保存退出。 6.3 查看端口是否被占用 查看端口是否被占用（以 3000 为例），输入： lsof -i:3000 #查看 3000 端口是否被占用，如果被占用，重新自定义一个端口 如果啥也没出现，表示端口未被占用，我们可以继续下面的操作了～ 如果出现： -bash: lsof: command not found 运行： apt install lsof #安装 lsof 如果端口没有被占用（被占用了就修改一下端口，比如改成 8381，注意 docker 命令行里和防火墙都要改） 6.4 启动 enclosed cd /root/data/docker_data/enclosed docker compose up -d # 注意，老版本用户用 docker-compose up -d 等待拉取好镜像，出现 done的字样之后， 理论上我们就可以输入 http://ip:3000 访问了。 但是这边这个服务必须先搞一下反向代理！不然会报错！ 做反向代理前，你需要一个域名！ namesilo 上面 xyz 后缀的域名一年就 7 块钱，可以年抛。（冷知识，namesilo 上 6 位数字的 xyz 续费永远都是 0.99 美元 = =） 如果想要长期使用，还是建议买 com 后缀的域名，更加正规一些，可以输入 laodade 来获得 1 美元的优惠（不知道现在还有没有） namesilo 自带隐私保护，咕咕一直在用这家，价格也是这些注册商里面比较低的，关键是他家不像其他家域名注册商，没有七七八八的套路！（就是后台界面有些丑 古老 = =） 【域名购买】Namesilo 优惠码和域名解析教程（附带服务器购买推荐和注意事项） 我们接着往下看！ 7. 反向代理 7.1 利用 Nginx Proxy Manager 在添加反向代理之前，确保你已经完成了域名解析，不会的可以看这个：域名一枚，并做好解析到服务器上（域名购买、域名解析 视频教程） 之后，登陆 Nginx Proxy Manager（不会的看这个：安装 Nginx Proxy Manager（相关教程）） 注意： Nginx Proxy Manager（以下简称 NPM）会用到 80、443 端口，所以本机不能占用（比如原来就有 Nginx） 直接丢几张图： 注意填写对应的 域名、IP 和 端口，按文章来的话，应该是 3000 IP 填写： 如果 Nginx Proxy Manager 和 enclosed 在同一台服务器上，可以在终端输入： ip addr show docker0 查看对应的 Docker 容器内部 IP。 否则直接填 enclosed 所在的服务器 IP 就行。 7.2 利用宝塔面板 发现还是有不少小伙伴习惯用宝塔面板，这边也贴一个宝塔面板的反代配置： 直接新建一个站点，不要数据库，不要 php，纯静态即可。 然后打开下面的配置，修改 Nginx 的配置。 代码如下： location / { proxy_pass http://127.0.0.1:3000/; # 注意改成你实际使用的端口 rewrite ^/(.*)$ /$1 break; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade-Insecure-Requests 1; proxy_set_header X-Forwarded-Proto https; } 此方法对 90% 的反向代理都能生效，然后就可以用域名来安装访问了。 有同学可能会问，为什么不直接用宝塔自带的反向代理功能。 也可以，不过咕咕自己之前遇到过当有多个网站需要反代的时候，在这边设置会报错的情况 = = 所以后来就不用了，直接用上面的方法来操作了。 8. 使用教程 8.1 登录网页 这个使用就很简单了，一目了然。 需要注意的是，你可以在添加文本的同时再添加附件，也是 OK 的。 8.2 更新 enclosed cd /root/data/docker_data/enclosed docker-compose pull docker-compose up -d # 请不要使用 docker-compose stop 来停止容器，因为这么做需要额外的时间等待容器停止；docker-compose up -d 直接升级容器时会自动停止并立刻重建新的容器，完全没有必要浪费那些时间。 docker image prune # prune 命令用来删除不再使用的 docker 对象。删除所有未被 tag 标记和未被容器使用的镜像 提示： WARNING! This will remove all dangling images. Are you sure you want to continue? [y/N] 输入 y 利用 Docker 搭建的应用，更新非常容易～ 8.3 卸载 enclosed 同样进入安装页面，先停止所有容器。 cd /root/data/docker_data/enclosed docker-compose down cd .. rm -rf /root/data/docker_data/enclosed # 完全删除 可以卸载得很干净。 9. 常见问题及注意点 暂时没有。 10. 结尾 祝大家用得开心，有问题可以去 GitHub 提 Issues，也可以在评论区互相交流探讨。 同时，项目处于初期，有能力给项目做贡献的同学，也欢迎积极加入到 项目 中来，贡献自己的一份力量！ 最后，感谢开发人员们的辛苦付出，让我们能用到这么优秀的项目！ 参考资料 官方 GitHub：https://github.com/enclosed/enclosed ","link":"https://pandajackpragrammer.github.io/post/enclosed/"},{"title":"HivisionIDPhoto---证件照智能","content":"🚀 项目简介 HivisionIDPhoto 旨在开发一种实用、系统性的证件照智能制作算法。 它利用一套完善的 AI 模型工作流程，实现对多种用户拍照场景的识别、抠图与证件照生成。 HivisionIDPhoto 可以做到： 🐷 轻量级抠图（纯离线，仅需 CPU 即可快速推理） 🐸 根据不同尺寸规格生成不同的标准证件照、六寸排版照 🐵 支持 纯离线 或 端云 推理 🐔 美颜（waiting） 🐺 智能换正装（waiting） 项目地址：https://swanhub.co/ZeYiLin/HivisionIDPhotos ","link":"https://pandajackpragrammer.github.io/post/hivisionidphoto/"},{"title":"华为虚拟化openEuler release 22.03 安装VMTools","content":"虚拟化平台：华为Fusioncompute 6.5.1.SPH6 X86 虚拟机操作系统：openEuler release 22.03 (LTS-SP1) VMTools版本：vmtools-2.5.0.155.tar.bz2 默认vmtools不支持openEuler release 22.03 (LTS-SP1)版本，需要修改安装脚本 vim /root/vmtools/install ### determine linux distribution issue='/etc/issue' if [ -e '/etc/debian_version' -o -n &quot;$(grep -i 'debian' $issue)&quot; ] then SYS_TYPE='debian' KERN_RELEASE=&quot;$(uname -r)&quot; CPU_ARCH=&quot;$(uname -m)&quot; INIT_TYPE='sysv' PIDPATH='/var/run' RC_SYSINIT='/etc/init.d/rc.local' ## 插入以下文本 elif [ -e '/etc/openEuler-release' ] then SYS_TYPE='openEuler' KERN_RELEASE=&quot;$(uname -r)&quot; CPU_ARCH=&quot;$(uname -m)&quot; INIT_TYPE='sysv' PIDPATH='/var/run' ## 在$SYS_TYPE&quot; = &quot;redhat&quot; 后增加 -o &quot;$SYS_TYPE&quot; = &quot;openEuler&quot; # Redhat-based systems if [ &quot;$SYS_TYPE&quot; = &quot;redhat&quot; -o &quot;$SYS_TYPE&quot; = &quot;openEuler&quot; ] then if ! chkconfig --del $srv_name &gt; /dev/null 2&gt;&amp;1 then $Info &quot;Disable $srv_name failed.&quot; warn &quot;Disable $srv_name failed.&quot; fi 安装服务 ./install 启动服务 systemctl start vm-agent 查看服务状态 systemctl status vm-agent 配置开机自启 systemctl enable vm-agent 查看虚拟VMTools状态 ","link":"https://pandajackpragrammer.github.io/post/vmtools/"},{"title":"明心","content":" 我观观音观自在，我见真武见真我 解开昔日旧枷锁，今日方知我是我 踏破尘世千重浪，心中方显菩提果 明悟本心归真道，此生始得自在活 ","link":"https://pandajackpragrammer.github.io/post/ming-xin/"},{"title":"国学：小六壬","content":" ","link":"https://pandajackpragrammer.github.io/post/xiaoliuren/"},{"title":"HelloWindows","content":"精校 完整 极致 Windows系统下载仓储站 🎅无广告、无登录限制、无收费下载。一个干净纯粹的系统仓储站，🍤更简单，更直观，更极致。 👉链接在这 ","link":"https://pandajackpragrammer.github.io/post/hellowindows/"},{"title":"RSS :Awesome TTRSS","content":"👉官网在这 🍒Tiny Tiny RSS (opens new window)是一款基于 PHP 的免费开源 RSS 聚合阅读器。🐋 Awesome TTRSS 旨在提供一个 「一站式容器化」 的 Tiny Tiny RSS 解决方案，通过提供简易的部署方式以及一些额外插件，以提升用户体验。 ","link":"https://pandajackpragrammer.github.io/post/awesome-ttrss/"},{"title":"自媒体运营管理工具：openwrite","content":"👉官网在这 🚗这是由一群来自互联网公司的技术自媒体人搭建的自媒体运营管理工具。比起图文编辑器，我们更爱用Markdown写文章；比起刷头条抖音，我们更爱看CSDN、博客园、开源中国；比起重复的劳力，我们更爱思考是否有更高效的技术解决方案！ 在线写作 🍷提供 Markdown 编辑器，支持自动保存、自定义图床、华丽的代码渲染等强大功能，用户完全可以通过 OpenWrite 在线完成创作。 一文多发 🚌在通过 Markdown 完成内容创作之后，OpenWrite 提供了非常便捷的方式让您的创作快速分发到名大内容平台。 导流工具 🚎实现每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的 微信公众号编辑器 🚲款开源 Markdown 编辑器，写完后即排版成功，复制即可粘贴到微信公众号。支持零配置图床、脚注、代码、公式、自定义样式等 ","link":"https://pandajackpragrammer.github.io/post/openwrite/"},{"title":"转载：Xpath小记","content":"本文转自：https://blog.csdn.net/xiaobai729/article/details/124079260#Xpath_3 文章目录 一、Xpath 简介 二、Xpath 语法规则 语法规则 标签定位 属性定位 索引定位 取文本内容 三、语法规则练习 前言 CSDN 上已经有很多大佬发过 Xpath，而且讲的都很好，我是因为刚开始学习网络爬虫，对这些基础重要知识不太了解，所以写一下来加深印象，本篇文章只是简单介绍一下 Xpath 及使用，总体来说比较基础。 一、Xpath 简介 XPath（XML Path Language - XML 路径语言），它是一种用来确定 XML 文档中某部分位置的语言。 Xpath 以 XML 为基础，提供用户在数据结构树中寻找节点的能力，Xpath 被很多开发者亲切的称为小型查询语言。 二、Xpath 语法规则 xpath 可以使用路径表达式在 XML 上选取节点，从而达到确认元素的目的，我们先来介绍以下语法规则。 语法规则 表达式作用nodename选取此层级节点下的所有子节点/代表从根节点进行选取//可以理解为匹配，就是在所有节点中选取此节点，直到匹配为止.选取当前节点…选取当前节点上一层（上一级目录）@选取属性（也是匹配） 标签定位 方式效果/html/body/div表示从根节点开始寻找，标签与标签之间 / 表示一个层级/html//div表示多个层级 作用于两个标签之间（也可以理解为在 html 下进行匹配寻找标签 div）//div从任意节点开始寻找，也就是查找所有的 div 标签./div表示从当前的标签开始寻找 div 属性定位 需求格式定位 div 中属性名为 href，属性值为‘www.baidu.com’的 div 标签@属性名 = 属性值href 为属性名'www.baidu.com’为属性值/html/body/div[href=‘www.baidu.com’] 索引定位 需求格式定位 ul 下第二个 li 标签 (下图)//ul/li[2]索引值开始位置为1 取文本内容 方法效果/text()获取标签下直系的标签内容//text()获取标签中所有的文本内容string()获取标签中所有的文本内容 在网页上获取 Xpath 其实很容易，直接找到标签后，右键复制就好了。 三、语法规则练习 接下来我们开始练习一下本地导入，加深一下理解，这个是一个比较简单的网页结构，我们先学会用法即可。 任务要求: 可以达到随心所欲的定位每一个元素 准备工作 #导入所需要的包 from lxml import etree #采用本地源码获取方式并加载到etree内 tree = etree.parse('test.html') 获取百度、谷歌、搜狗文本内容 #引用xpath方法并进行标签定位 #''.join是取字符串内的内容 text = ' '.join(tree.xpath('/html/body/ul/li/a/text()')) print(text) 2. 获取单个谷歌 text1 = tree.xpath(&quot;//ul/li[2]/a/text()&quot;)[0] print(text1) 3. 获取北京、上海、天津的属性值 text2 = ' '.join(tree.xpath(&quot;//ol/li/a/@href&quot;)) print(text2) 4. 获取河南文本 #获取河南文本 text3 = tree.xpath(&quot;/html/body/div[2]/text()&quot;)[0] print(text3) 5. 获取谷歌属性值 text4 = tree.xpath(&quot;//ul/li[2]/a/@href&quot;)[0] print(text4) 至此我们已经可以随心定位任意标签 完成任务 收工 ","link":"https://pandajackpragrammer.github.io/post/xpath-xiao-ji/"},{"title":"超星学习通pdf ppt MP4等在线浏览文件下载","content":"使用浏览器打开资源所在页面； 按F12或右键审查元素，点击network,在过滤条件输入flag=normal,刷新； 得到链接，在新标签页打开，找到.pdf或其他后缀url，即可下载！ ","link":"https://pandajackpragrammer.github.io/post/chaoxingxiazai/"},{"title":"转：Centos7 扩展磁盘空间（LVM 管理）","content":"原文转自：https://www.cnblogs.com/lenmom/p/9897739.html vmware 或 hyperv，扩容磁盘，本例中使用的是 vmware, 关闭系统，在 vmware—&gt; 设置—&gt; 硬盘—&gt; 扩展—&gt; 输入数字大于当前系统内存—&gt; 点击扩展, 如图： 1. 查看磁盘情况 fdisk -l /dev/sda Disk /dev/sda: 536.9 GB, 536870912000 bytes, 1048576000 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk label type: dos Disk identifier: 0x000ac88a Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 266338303 132119552 8e Linux LVM 2. 查看磁盘占用情况 df -lh Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 50G 24G 27G 47% / devtmpfs 5.8G 0 5.8G 0% /dev tmpfs 5.8G 84K 5.8G 1% /dev/shm tmpfs 5.8G 8.8M 5.8G 1% /run tmpfs 5.8G 0 5.8G 0% /sys/fs/cgroup /dev/sda1 1014M 173M 842M 18% /boot /dev/mapper/cl-home 69G 517M 68G 1% /home tmpfs 1.2G 16K 1.2G 1% /run/user/42 tmpfs 1.2G 0 1.2G 0% /run/user/0 创建新分区 fdisk /dev/sda 弹出的命令行中输入对应的命令，命令说明如下： Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) a) 命令行输入 n 创建新分区 [root@lenmom ~]# fdisk /dev/sda The device presents a logical sector size that is smaller than the physical sector size. Aligning to a physical sector (or optimal I/O) size boundary is recommended, or performance may be impacted. Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n b) 命令行输入 p 设置分区类型为主分区 Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p c) 设置分区数量，这里输入为 3 Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): 3 d) 修改分区大小，我们这里取默认大小，直接按两次回车即可（开始和结束位置） Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): 3 First sector (266338304-1048575999, default 266338304): Using default value 266338304 Last sector, +sectors or +size{K,M,G} (266338304-1048575999, default 1048575999): Using default value 1048575999 Partition 3 of type Linux and of size 373 GiB is set e) 输入 t 修改分区编号 Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): 3 First sector (266338304-1048575999, default 266338304): Using default value 266338304 Last sector, +sectors or +size{K,M,G} (266338304-1048575999, default 1048575999): Using default value 1048575999 Partition 3 of type Linux and of size 373 GiB is set Command (m for help): t Partition number (1-3, default 3): f）修改分区编号为 3 Command (m for help): n Partition type: p primary (2 primary, 0 extended, 2 free) e extended Select (default p): p Partition number (3,4, default 3): 3 First sector (266338304-1048575999, default 266338304): Using default value 266338304 Last sector, +sectors or +size{K,M,G} (266338304-1048575999, default 1048575999): Using default value 1048575999 Partition 3 of type Linux and of size 373 GiB is set Command (m for help): t Partition number (1-3, default 3): 3 Hex code (type L to list all codes): g) 选择分区格式, 我们选择 lvm，所以输入 8e Hex code (type L to list all codes): L 0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden C: c6 DRDOS/sec (FAT- 4 FAT16 &lt;32M 40 Venix 80286 85 Linux extended c7 Syrinx 5 Extended 41 PPC PReP Boot 86 NTFS volume set da Non-FS data 6 FAT16 42 SFS 87 NTFS volume set db CP/M / CTOS / . 7 HPFS/NTFS/exFAT 4d QNX4.x 88 Linux plaintext de Dell Utility 8 AIX 4e QNX4.x 2nd part 8e Linux LVM df BootIt 9 AIX bootable 4f QNX4.x 3rd part 93 Amoeba e1 DOS access a OS/2 Boot Manag 50 OnTrack DM 94 Amoeba BBT e3 DOS R/O b W95 FAT32 51 OnTrack DM6 Aux 9f BSD/OS e4 SpeedStor c W95 FAT32 (LBA) 52 CP/M a0 IBM Thinkpad hi eb BeOS fs e W95 FAT16 (LBA) 53 OnTrack DM6 Aux a5 FreeBSD ee GPT f W95 Ext'd (LBA) 54 OnTrackDM6 a6 OpenBSD ef EFI (FAT-12/16/ 10 OPUS 55 EZ-Drive a7 NeXTSTEP f0 Linux/PA-RISC b 11 Hidden FAT12 56 Golden Bow a8 Darwin UFS f1 SpeedStor 12 Compaq diagnost 5c Priam Edisk a9 NetBSD f4 SpeedStor 14 Hidden FAT16 &lt;3 61 SpeedStor ab Darwin boot f2 DOS secondary 16 Hidden FAT16 63 GNU HURD or Sys af HFS / HFS+ fb VMware VMFS 17 Hidden HPFS/NTF 64 Novell Netware b7 BSDI fs fc VMware VMKCORE 18 AST SmartSleep 65 Novell Netware b8 BSDI swap fd Linux raid auto 1b Hidden W95 FAT3 70 DiskSecure Mult bb Boot Wizard hid fe LANstep 1c Hidden W95 FAT3 75 PC/IX be Solaris boot ff BBT 1e Hidden W95 FAT1 80 Old Minix Hex code (type L to list all codes): 8e Changed type of partition 'Linux' to 'Linux LVM' h) 输入 w 保存分区并退出 Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. 4. 重启系统 reboot 5. 查看已有卷组名 vgdisplay --- Volume group --- VG Name cl System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 3 Max PV 0 Cur PV 1 Act PV 1 VG Size &lt;126.00 GiB PE Size 4.00 MiB Total PE 32255 Alloc PE / Size 32254 / 125.99 GiB Free PE / Size 1 / 4.00 MiB VG UUID zlg3Lh-rWHl-ozXP-FfIL-xs2w-yT7a-2k3VgA 在本机中卷组为 cl.(后面会用到) 6. 为新分配的空间创建一个新的物理卷 pvcreate /dev/sda3 Physical volume &quot;/dev/sda3&quot; successfully created. 注意：如果出现错误说 pvcreate 命令找不到，则执行： yum install pv 7. 使用新的物理卷来扩展 LVM 的 VolGroup vgextend cl /dev/sda3 这里的 cl 即为第 5 步中查出来的卷组名. 命令执行输出如下： [root@lenmom ~]# vgextend cl /dev/sda3 Volume group &quot;cl&quot; successfully extended 8. 扩展 LVM 的逻辑卷 /dev/cl/home a) 先查看逻辑卷集合 lvdisplay 输出如下： [root@lenmom ~]# lvdisplay --- Logical volume --- LV Path /dev/cl/swap LV Name swap VG Name cl LV UUID LM5xZa-J1Af-XPIu-CQYK-2JTw-Cw9N-JOmqdm LV Write Access read/write LV Creation host, time localhost.localdomain, 2018-05-31 15:37:32 +0800 LV Status available # open 2 LV Size &lt;7.88 GiB Current LE 2016 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:1 --- Logical volume --- LV Path /dev/cl/home LV Name home VG Name cl LV UUID U2TrdQ-ihpb-SNr3-U1cq-qOKr-4gw0-rYNmOG LV Write Access read/write LV Creation host, time localhost.localdomain, 2018-05-31 15:37:32 +0800 LV Status available # open 1 LV Size &lt;68.12 GiB Current LE 17438 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 --- Logical volume --- LV Path /dev/cl/root LV Name root VG Name cl LV UUID xXKaHg-WKW0-H3e2-dtjx-MJLS-bUcm-PpPw3z LV Write Access read/write LV Creation host, time localhost.localdomain, 2018-05-31 15:37:34 +0800 LV Status available # open 1 LV Size 50.00 GiB Current LE 12800 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 这里我们选择扩展 / dev/cl/home 逻辑卷 b）扩展逻辑卷 / dev/cl/home 空间 lvextend /dev/cl/home /dev/sda3 输出为： [root@lenmom ~]# lvextend /dev/cl/home /dev/sda3 Size of logical volume cl/home changed from &lt;68.12 GiB (17438 extents) to 441.11 GiB (112925 extents). Logical volume cl/home successfully resized. 可以看到原有的磁盘空间从 68G 扩展到了 441G, lvextend 参数 - L 是指定大小 如果不输入 - L +10G 则默认使用全部 9）调整逻辑卷的大小 xfs_growfs /dev/cl/home 输出为： [root@lenmom ~]# xfs_growfs /dev/cl/home meta-data=/dev/mapper/cl-home isize=512 agcount=4, agsize=4464128 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=17856512, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=8719, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 17856512 to 115635200 注意： 有些地方说要使用 resize2fs 命令更新系统识别的文件系统大小，但是亲测要使用 xfs_growfs 命令。 10） 检验结果 [root@lenmom ~]# lvscan ACTIVE '/dev/cl/swap' [&lt;7.88 GiB] inherit ACTIVE '/dev/cl/home' [441.11 GiB] inherit ACTIVE '/dev/cl/root' [50.00 GiB] inherit 也可以使用下面的方式来检验 [root@palolenmom ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 50G 14G 37G 27% / devtmpfs 5.8G 0 5.8G 0% /dev tmpfs 5.8G 84K 5.8G 1% /dev/shm tmpfs 5.8G 8.7M 5.8G 1% /run tmpfs 5.8G 0 5.8G 0% /sys/fs/cgroup /dev/sda1 1014M 173M 842M 18% /boot /dev/mapper/cl-home 442G 23G 419G 6% /home tmpfs 1.2G 16K 1.2G 1% /run/user/42 tmpfs 1.2G 0 1.2G 0% /run/user/0 常见错误 resize2fs /dev/cl/root resize2fs 1.44.3 (10-July-2018) resize2fs: 超级块中的幻数有错 尝试打开 /dev/cl/root 时 找不到有效的文件系统超级块。 使用命令解决，/ 代表 逻辑分区实际挂载的路径 xfs_growfs / ","link":"https://pandajackpragrammer.github.io/post/centos7kuozhancipan/"},{"title":"开源的聊天机器人框架","content":"🥝最近，ChatGPT大火，也带动了AI技术的话题热度，在这里整理一些开源的ChatBot框架 不断更新中。。。 1、Koishi聊天机器人 😊Koishi 提供了高度便利的控制台，让你无需基础让你在几分钟之内搭建自己的聊天机器人。 提供在线插件市场，即使没有任何编程基础，也能轻松在控制台中下载安装插件 支持 QQ，Telegram，Discord 等主流聊天平台，支持多账户和跨平台数据互通 随时随地通过控制面板监控运行状态，控制机器人的行为，甚至上号聊天 Github项目地址：Koishi 2、思知（OwnThink） 🎄本项目开放了对话机器人、知识图谱、语义理解、自然语言处理工具。知识图谱融合了两千五百多万的实体，拥有亿级别的实体属性关系，机器人采用了基于知识图谱的语义感知与理解，致力于最强认知大脑。自然语言处理工具包的功能有：中文分词、词性标注、命名实体识别、关键词提取、文本摘要、新词发现、情感分析等。 思知（OwnThink） 3、青云客智能聊天机器人 🐉提供聊天机器人接口 4、GO-FLY 🥙开源在线客服系统GO语言开发GO-FLY,免费在线客服系统GOFLY 基于Golang语言和MySQL实现的WEB在线客服系统 5、开源chatbot项目 🍦一个可以自己进行训练的中文聊天机器人， 根据自己的语料训练出自己想要的聊天机器人，可以用于智能客服、在线问答、智能聊天等场景。目前包含seq2seq、seqGAN版本、tf2.0版本、pytorch版本。 6、Leon 🍜Leon是一个开源的个人助理，可以通过离线方式与您交流以保护您的隐私。 Github项目地址：Leon 7、春松客服 🍇春松客服是拥有坐席管理、渠道管理、机器人客服、数据分析、CRM 等功能于一身的新一代客服系统。 Github项目地址：春松客服 8、小智聊天机器人 💖 利用有趣的中文语料库qingyun，由@Doragd 同学编写的中文聊天机器人⛄ 9、ChatterBot 🍫ChatterBot是Python自带的基于机器学习的语音对话引擎，可以基于已知的对话库来产生回应。ChatterBot独特的语言设计可以使它可以通过训练来用任何一种语言进行对话。🍝 10、腾讯对话开放平台 🍟支持扫码一键绑定小程序、公众号、企业微信、微信客服等，还有H5与API接口提供，关键是免费！免费！🍊 ","link":"https://pandajackpragrammer.github.io/post/jiqirenkuangjia/"},{"title":"开发运维人员必备的在线工具网站汇总","content":"不断更新中。。。 1、奇Q工具网 🍑在线Cron表达式生成器很好用🍉 2、爱资料工具 🍕工具很丰富🍊 3、在线工具 🍦不光有比较齐全的在线工具，还有码库与文库（🐼强力推荐!!!） 4、便民查询网 🥝查询功能很丰富，很实用🍇 5、资源在线解析 🍬支持视频图片去水印、音乐解析、免费接口服务TenAPI（🐼强力推荐!!!） 6、MD5在线加密解密 🥕用于md5、sha1、mysql、ntlm等的实时解密，拥有强大的反向解析库（众所周知MD5加密是单项的，实测解密效果不理想，但是简单一些的解密还是可以的，反而加密功能比较好用）🍖 7、老北鼻AI站 🍓好多免费的AI工具，包括ChatGPT,我只想说很香🍅 8、IT技术之家的GPT地址发布页 ","link":"https://pandajackpragrammer.github.io/post/gongjuwangzhan/"},{"title":"Excel生成随机的32位id","content":"在Excel用公式随机生成32位的随机id（无符号，只有数字和小写字母）🍓 =LOWER(CONCATENATE(DEC2HEX(RANDBETWEEN(0,POWER(16,8)),8),&quot;&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,4)),4),&quot;&quot;,&quot;4&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,3)),3),&quot;&quot;,DEC2HEX(RANDBETWEEN(8,11)),DEC2HEX(RANDBETWEEN(0,POWER(16,3)),3),&quot;&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,8)),8),DEC2HEX(RANDBETWEEN(0,POWER(16,4)),4))) ⚽️示例：620e65bc427c32702917fd8dfaebb2df 🍑🍒🍎🍐🍊🍋🍌🍉🍇 如果需要大写把LOWR函数去掉即可 🥐🍤利用宏生成32位ID 自动生成填充到以A列的行数为基准的行 🍒🍑VBA代码如下 Sub 自动填充32位id() ' ' 自动填充32位id 宏 ' ' ActiveWindow.SmallScroll Down:=-9 ActiveCell.Select ActiveCell.FormulaR1C1 = _ &quot;=LOWER(CONCATENATE(DEC2HEX(RANDBETWEEN(0,POWER(16,8)),8),&quot;&quot;&quot;&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,4)),4),&quot;&quot;&quot;&quot;,&quot;&quot;4&quot;&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,3)),3),&quot;&quot;&quot;&quot;,DEC2HEX(RANDBETWEEN(8,11)),DEC2HEX(RANDBETWEEN(0,POWER(16,3)),3),&quot;&quot;&quot;&quot;,DEC2HEX(RANDBETWEEN(0,POWER(16,8)),8),DEC2HEX(RANDBETWEEN(0,POWER(16,4)),4)))&quot; r = Cells(Rows.Count, &quot;A&quot;).End(xlUp).Row Selection.AutoFill Destination:=ActiveCell.Range(&quot;A1:A&quot; &amp; r), Type:= _ xlFillDefault r = Cells(Rows.Count, &quot;A&quot;).End(xlUp).Row ActiveCell.Range(&quot;A1:A&quot; &amp; r).Select Selection.Copy Selection.PasteSpecial Paste:=xlPasteValues, Operation:=xlNone, SkipBlanks _ :=False, Transpose:=False End Sub ","link":"https://pandajackpragrammer.github.io/post/excelshengcheng/"},{"title":"markdown常用语法汇总","content":"1.标题 使用#号标记，可以表示1-6级标题，随#个数递增。如： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 注：最后一个#与文字间一定要有一个空格。 显示效果如下： 一级标题 二级标题 三级标题 四级标题 五级标题 六级标题 2.字体 *斜体文本* _斜体文本_ **粗体文本** __粗体文本__ ***粗斜体文本*** ___粗斜体文本___ 把你想修改的字段直接放在中间即可。显示效果如下： 斜体文本 斜体文本 粗体文本 粗体文本 粗斜体文本 粗斜体文本 3.换行 使用&lt;br/&gt;标签 使用&amp;nbsp; 4、分割线 *** * * * ***** - - - ---------- 效果如下： ## 5、删除线、下划线 ~~删除线~~ &lt;u&gt;下滑线&lt;/u&gt; 删除线 下划线 6、插入代码 插入一行代码： `我是一行代码；` //英文输入法下，键盘左上角tab键上面那个符号 我是一行代码； 插入代码块： ```紧跟着可以写上用的什么语言，也可以不用写 我是代码块； ```结尾跟开头一样 7、插入链接(所有符号都是英文输入法下的) [链接名称](链接地址) 或者 &lt;链接地址&gt; 我是PandaJack http://www.pandajack.top 8、字体颜色 浅红色文字：&lt;font color=&quot;#dd0000&quot;&gt;浅红色文字：&lt;/font&gt;&lt;br /&gt; 深红色文字：&lt;font color=&quot;#660000&quot;&gt;深红色文字&lt;/font&gt;&lt;br /&gt; 浅绿色文字：&lt;font color=&quot;#00dd00&quot;&gt;浅绿色文字&lt;/font&gt;&lt;br /&gt; 深绿色文字：&lt;font color=&quot;#006600&quot;&gt;深绿色文字&lt;/font&gt;&lt;br /&gt; 浅蓝色文字：&lt;font color=&quot;#0000dd&quot;&gt;浅蓝色文字&lt;/font&gt;&lt;br /&gt; 深蓝色文字：&lt;font color=&quot;#000066&quot;&gt;深蓝色文字&lt;/font&gt;&lt;br /&gt; 浅黄色文字：&lt;font color=&quot;#dddd00&quot;&gt;浅黄色文字&lt;/font&gt;&lt;br /&gt; 深黄色文字：&lt;font color=&quot;#666600&quot;&gt;深黄色文字&lt;/font&gt;&lt;br /&gt; 浅青色文字：&lt;font color=&quot;#00dddd&quot;&gt;浅青色文字&lt;/font&gt;&lt;br /&gt; 深青色文字：&lt;font color=&quot;#006666&quot;&gt;深青色文字&lt;/font&gt;&lt;br /&gt; 浅紫色文字：&lt;font color=&quot;#dd00dd&quot;&gt;浅紫色文字&lt;/font&gt;&lt;br /&gt; 深紫色文字：&lt;font color=&quot;#660066&quot;&gt;深紫色文字&lt;/font&gt;&lt;br /&gt; 浅红色文字：浅红色文字： 深红色文字：深红色文字 浅绿色文字：浅绿色文字 深绿色文字：深绿色文字 浅蓝色文字：浅蓝色文字 深蓝色文字：深蓝色文字 浅黄色文字：浅黄色文字 深黄色文字：深黄色文字 浅青色文字：浅青色文字 深青色文字：深青色文字 浅紫色文字：浅紫色文字 深紫色文字：深紫色文字 9、字体 &lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt; &lt;font face=&quot;宋体&quot;&gt;我是宋体字&lt;/font&gt; &lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑字&lt;/font&gt; &lt;font face=&quot;fantasy&quot;&gt;我是fantasy字&lt;/font&gt; &lt;font face=&quot;Helvetica&quot;&gt;我是Helvetica字&lt;/font&gt; 我是黑体字 我是宋体字 我是微软雅黑字 我是fantasy字 我是Helvetica字 10、字体大小 size为1：&lt;font size=&quot;1&quot;&gt;size为1&lt;/font&gt;&lt;br /&gt; size为2：&lt;font size=&quot;2&quot;&gt;size为2&lt;/font&gt;&lt;br /&gt; size为3：&lt;font size=&quot;3&quot;&gt;size为3&lt;/font&gt;&lt;br /&gt; size为4：&lt;font size=&quot;4&quot;&gt;size为4&lt;/font&gt;&lt;br /&gt; size为10：&lt;font size=&quot;10&quot;&gt;size为10&lt;/font&gt;&lt;br /&gt; size为1：size为1 size为2：size为2 size为3：size为3 size为4：size为4 size为10：size为10 11、背景色 &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=#FF00FF&gt;背景色的设置是按照十六进制颜色值：#7FFFD4&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=#FF83FA&gt;背景色的设置是按照十六进制颜色值：#FF83FA &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=#D1EEEE&gt;背景色的设置是按照十六进制颜色值：#D1EEEE &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=#C0FF3E&gt;背景色的设置是按照十六进制颜色值：#C0FF3E &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=#54FF9F&gt;背景色的设置是按照十六进制颜色值：#54FF9F &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;table&gt; &lt;tr&gt; &lt;td bgcolor=DarkSeaGreen&gt;这里的背景色是：DarkSeaGreen，此处输入任意想输入的内容 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 背景色的设置是按照十六进制颜色值：#7FFFD4 背景色的设置是按照十六进制颜色值：#FF83FA 背景色的设置是按照十六进制颜色值：#D1EEEE 背景色的设置是按照十六进制颜色值：#C0FF3E 背景色的设置是按照十六进制颜色值：#54FF9F 这里的背景色是：DarkSeaGreen，此处输入任意想输入的内容 ","link":"https://pandajackpragrammer.github.io/post/markdownyufa/"},{"title":"免费的API接口","content":"1、今日诗词API接口 今日诗词官网 正在加载今日诗词.... 在 HTML 中需要加载诗词的地方放置以下加载代码即可, 和 网站统计 的安装方法一致 &lt;span id=&quot;jinrishici-sentence&quot;&gt;正在加载今日诗词....&lt;/span&gt; &lt;script src=&quot;https://sdk.jinrishici.com/v2/browser/jinrishici.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; 还支持图片直接调用，小程序，安卓，iOS，Vue 、 React 框架等接入，有需要的可以去官网探索 2、免费的API接口服务TenAPI TenAPI官网 🌞免费的接口很多，👉文档入口在这里 ","link":"https://pandajackpragrammer.github.io/post/apijiekou/"},{"title":"数据库转换：sqllite 数据库转换成 mysql 数据库","content":"工具：Navicat 用 Navicat 分别连接 sqllite 与 mysql（新建一个库） 一、删除 sqllite 的所有索引 二、打开 Navicat 工具 --- 数据传输 左边选 sqlite 的库，右边选创建的 mysql 的库，下一步，确定所要同步的表，然后开始 此时可能会报一个错误 #1366 - Incorrect integer value: '' for column 'id' at row 1 三、修改 mysql 的配置文件 my.ini my.ini 中查找 sql-mode，默认为 sql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&quot; 将其修改为 (如果找不到，直接添加以下配置即可) sql-mode=&quot;NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&quot; 重启 mysql，然后再按第二步重新进行数据传输操作即可。 ","link":"https://pandajackpragrammer.github.io/post/shu-ju-ku-zhuan-huan-sqllite-shu-ju-ku-zhuan-huan-cheng-mysql-shu-ju-ku/"},{"title":"iperf3---- 网络吞吐量测试工具","content":"iperf3 命令是一个执行网络吞吐量测量的工具； 它可以测试 TCP 或 UDP 的吞吐量， 要执行 iperf3 测试，用户必须同时建立一个服务器和一个客户端。 一、安装 iperf3 1、yum 安装 yum install -y iperf3 2、其他操作系统可以下载官网的软件包 iperf3 下载链接：iPerf - Download iPerf3 and original iPerf pre-compiled binaries 下载完成后可以通 “rpm -ivh” 进行安装。 二、Linux 操作系统测速 1、开启 ipert3 服务器端 iperf3 -s iperf3 -s -p 2222 #可以指定服务器测试的端口号； 2、客户端测速命令 iperf3 -c 172.16.0.211 #连接测速，默认测的是从客户端到服务端的带宽（服务器接收，客户端发送） 三、Windows 操作系统测速 下载 windows 测速工具，后打开 CMD，执行与 linux 相同的命令即可测速。如下图： 四、iperf3 常用命令 **语法格式：**iperf3 [参数] 常用参数 p服务端监听或客户端连接的端口，默认端口：5201-s启动服务端监听-f格式化带宽输出：Kbits, Mbits, Kbytes, Mbytes-i以秒为单位周期性输出带宽报告，默认显示时间间隔为 1 秒，0 表示不显示-F传输或接收特定的文件-B绑定特定的接口-d显示调试输出信息-J以 JSON 格式输出-V显示更多详细的输出 参考实例 开启服务端监听： [root@linuxcool ~]# iperf3 -s 开启服务端监听并设置自定义监听端口： [root@linuxcool ~]# iperf3 -s -p 5208 启动调试模式： [root@linuxcool ~]# iperf3 -s -d 以 JSON 格式输出： [root@linuxcool ~]# iperf3 -s -J 显示更多详细的输出： [root@linuxcool ~]# iperf3 -s -V 客户端显示服务端输出信息： iperf3 -c 服务端ip --get-server-output ","link":"https://pandajackpragrammer.github.io/post/iperf3/"},{"title":"获取公众号的关注链接_关注公众号链接","content":"获取公众号的关注链接只需获取公众号的_biz 参数，将下列链接 biz 替换即可 https://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=MzI3MjQ0MDY3OA== 详情请自行百度，此文介绍如何获取公众号的_biz 参数 随意打开公众号的一篇文章，左上角复制链接，用谷歌浏览器打开，按 F12 打开开发者选项 取消勾选 User agent 并将下方输入框加入底下的这段手机参数 然后鼠标随便点一下空白处更新设置: Mozilla/5.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Mobile/12A365 MicroMessenger/5.4.1 NetType/WIFI 然后我们刷新页面： 打开 payload 查看发现有我们需要的__biz 的参数，得到的链接在微信中打开验证 https://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=MzI3MjQ0MDY3OA== ","link":"https://pandajackpragrammer.github.io/post/gongzhonghaolianjie/"},{"title":"Linux 解压缩命令简介及解压缩命令使用_.tgz 怎么解压","content":"一、解压缩命令简介 tar 命令 -c: 建立压缩档案 -x：解压 -t：查看内容 -r：向压缩归档文件末尾追加文件 -u：更新原压缩包中的文件 这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。 -z：有gzip属性的 -j：有bz2属性的 -Z：有compress属性的 -v：显示所有过程 -O：将文件解开到标准输出 下面的参数 - f 是必须的 -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。 # tar -cf all.tar *.jpg这条命令是将所有。jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 # tar -rf all.tar *.gif这条命令是将所有。gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 # tar -uf all.tar logo.gif这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 # tar -tf all.tar这条命令是列出all.tar包中所有文件，-t是列出文件的意思 # tar -xf all.tar这条命令是解出all.tar包中所有文件，-x是解开的意思 二、压缩命令使用 tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg tar –czf jpg.tar.gz *.jpg // 将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2 tar –cZf jpg.tar.Z *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux 三、解压命令使用 tar –xvf file.tar //解压 tar包 tar -xzvf file.tar.gz //解压tar.gz tar -xjvf file.tar.bz2 //解压 tar.bz2 tar –xZvf file.tar.Z //解压tar.Z unrar e file.rar //解压rar unzip file.zip //解压zip 四、总结 1、*.tar 用 tar –xvf 解压 2、*.gz 用 gzip -d或者gunzip 解压 3、*.tar.gz和*.tgz 用 tar –xzf 解压 4、*.bz2 用 bzip2 -d或者用bunzip2 解压 5、*.tar.bz2用tar –xjf 解压 6、*.Z 用 uncompress 解压 7、*.tar.Z 用tar –xZf 解压 8、*.rar 用 unrar e解压 9、*.zip 用 unzip 解压 ","link":"https://pandajackpragrammer.github.io/post/linuxjieyasuo/"},{"title":"netstat  -tunlp 命令小记","content":"netstat -tunlp 主要用来查看端口占用情况 t：表示查看tcp u：表示查看udp p：表示占用端口的进程 n：表示端口以数字形式表示，没有n直接显示服务名 l：表示显示所监听的端口 使用实例： netstat -tunlp #直接查看所有端口占用情况 netstat -tunlp | grep 端口号 #查看指定端口占用情况 ","link":"https://pandajackpragrammer.github.io/post/netstattunlp/"},{"title":"挂载光盘出现写保护 mount_ block device _dev_sr0 is write-protected, mounting read-only","content":"解决办法： mount -t iso9660 /dev/sr0 目标文件夹 这句话的意思是把你的 cd 驱动器挂载到目标文件系统下面 iso9660 是标准的 cd 文件格式，它告诉 mount 命令，我要 挂载的是一个标准的 cd。 ","link":"https://pandajackpragrammer.github.io/post/guazaiguangpan/"},{"title":"常用 DOS 命令","content":"常用目录命令 ========== md/mkdir 作用：创建一个子目录（make directory）。 语法：md[C:][path]〈subPath〉 cd 作用：改变或显示当前目录（change directory）。 语法：cd [C:][path] PS：路径可以使用绝对路径和相对路径两种。 cd\\ 表示退回到根目录。 cd.. 表示退回到上级目录。 如果只有cd而没有参数，则只显示当前路径。 注意：子目录中一定有两个“特殊目录”，即“.”“..”，其中一点表示当前目录，两点表示上一层目录。 从简单实用的角度来看，我们只要学会逐层进入（cd 下一层某目录名），和逐层退出（cd..）就可以解决所有问题。 rd 作用：删除空子目录（remove directory）。 语法：rd [c:][path] PS：rd是专门删除空子目录的命令。 del 删除文件命令。 注意两条：一是不能删除非空目录；二是不能删除当前目录。 dir 作用：主要用来显示一个目录下的文件和子目录。(directory) 语法：dir [C:][path][filename][/o][/s][/p][/w][/a] PS：斜杠表示后面的内容是参数。 /p 显示信息满一屏时，暂停显示，按任意键后显示下一屏 /o 排序显示。o后面可以接不同意义的字母 /w 只显示文件名目录名，每行五个文件名。即宽行显示 /s 将目录及子目录的全部目录文件都显示 /a 显示隐藏文件 path 作用：设备可执行文件的搜索路径，只对文件有效。 语法：path[盘符1：][路径1][盘符2：][路径2]… PS：当运行一个可执行文件时，dos会先在当前目录中搜索该文件，若找到则运行之；若找不到该文件，则根据path命令所设置的路径，顺序逐条地到目录中搜索该文件 tree 作用：显示指定驱动器上所有目录路径和这些目录下的所有文件名。 语法：tree [盘符：][/f][&gt;prn] deltree 作用：删除目录树。 语法：DELTREE [C1:][path1] PS：这个命令将整个指定目录树全部消灭，而不管它是否是只读、隐藏与否。使用应特别小心。它是一个危险命令。 tasklist 作用：将整个计算机的进程显示出来，同任务管理器。 语法：tasklist 常用磁盘命令 format 作用：磁盘格式化。 语法：format〈盘符：〉[/s][/4][/q] unformat 作用：对进行过格式化误操作丢失数据的磁盘进行恢复。 语法：unformat〈盘符〉[/l][/u][/p][/test] chkdsk 作用：显示磁盘状态、内存状态和指定路径下指定文件的不连续数目。 语法：chkdsk [盘符：][路径][文件名][/f][/v] PS：PS：例如要检查A盘使用情况，就输入chkdsk A: ，检查c盘使用情况，就输入chkdsk C: ，如果直接输入chkdsk，就检查当前磁盘的使用情况。 diskcopy 作用：复制格式和内容完全相同的软盘。 语法：diskcopy[盘符1：][盘符2：] label 作用：建立、更改、删除磁盘卷标。 语法：label[盘符：][卷标名] vol 作用：查看磁盘卷标号。 语法：vol[盘符：] scandisk 作用：检测磁盘的fat表、目录结构、文件系统等是否有问题，并可将检测出的问题加以修复。 语法：scandisk[盘符1：]{[盘符2：]…}[/all] defrag 作用：整理磁盘，消除磁盘碎块。 语法：defrag[盘符：][/f] PS：选用/f参数，将文件中存在盘上的碎片消除，并调整磁盘文件的安排，确保文件之间毫无空隙。从而加快读盘速度和节省磁盘空间。 sys 作用：将当前驱动器上的dos系统文件io.sys,msdos.sys和command 传送到指定的驱动器上。 语法：sys[盘符：] 常用文件命令 copy 作用：拷贝一个或多个文件到指定盘上。 语法：copy [源盘][路径]（源文件名） [目标盘][路径](目标文件名） xcopy 作用：复制指定的目录和目录下的所有文件连同目录结构。 语法：xcopy [源盘：]〈源路径名〉[目标盘符：][目标路径名][/s][/v][/e] PS：xcopy是copy的扩展，可以把指定的目录连文件和目录结构一并拷贝，但不能拷贝隐藏文件和系统文件。 type 作用：显示ascii码文件的内容。 语法：type [C:][path][filename.ext] PS：type命令用来在屏幕上快速、简便地显示文本文件的内容，扩展名为TXT的文件是文本文件。 ren 作用：对指定磁盘、目录中的一个文件或一组文件更改名称（rename）。 语法：ren[盘符：][路径]〈旧文件名〉〈新文件名〉 PS：改名操作只限于某个文件某组文件的名称，它不会更改文件所在的目录。 fc 作用：比较文件的异同，并列出差异处。 语法：fc[盘符：][路径名]〈文件名〉[盘符：][路径名][文件名][/a][/c][/n] attrib 作用：修改指定文件的属性。 语法：attrib[文件名][r][—r][a][—a][h][—h][—s] del 作用：删除指定的文件。 语法：del[盘符：][路径]〈文件名〉[/p] undelete 作用：恢复被误删除文件。 语法：undelete[盘符：][路径名]〈文件名〉[/dos][/list][/all] ping 命令 Ping命令的独特用法 作用：Ping命令不仅可以测试网络是否通，而且还可以粗略的判断网络传输质量。 语法：ping +空格+“IP地址或者域名” [-t][-l][-n] PS： -t：不停的Ping对方的机器，直到用户按Ctrl＋C键终止。因为如果想用Ping命令测试网络传输质量，至少要查看Ping命令三分钟到五分钟的结果。 -l：定义echo数据包大小。我们可以将数据包的大小定义在极限值附近，以此可以测试出网络传输质量的优劣，尤其是测试外网的传输质量，非常明显。 -n：在默认情况下，Ping命令一般都会发送四个数据包，通过这个命令可以自己定义发送的个数，对测试网络传输质量很有帮助。我们结合实例说明一下如何通过Ping命令的测试结果判断网络传输质量。 tracert 命令的使用技巧 作用：tracert命令可以测试路由器的工作是否正常（部分网站无法访问）。 我们根据返回的结果来判断，哪一个环节的网络出现了问题。 语法：tracert +空格+“IP地址或者域名” 用 netstat 命令判断是否被攻击 作用：netstat命令可以查看单位的网络是否被攻击。 语法：netstat [-a][-n][-b] PS： -a：显示所有连接和监听端口 -n：以数字形式显示地址和端口号 -b：显示包含于创建每个连接或监听端口的可执行组件。另外，使用该参数之后，还可以显示占用TCP协议端口的一些程序名称 巧用 ARP 命令防范 ARP 病毒 作用：Ping命令不仅可以测试网络是否通，而且还可以粗略的判断网络传输质量。 语法：arp -s ip地址 MAC 灵活使用 ipconfig 命令 作用：ipconfig这个命令查看计算机当前的网络配置信息。 ps： ipconfig /all：完全显示计算机的网络信息，IP地址、MAC地址及其他相关的信息，都可以显示出来。 ipconfig /release：释放计算机当前获得的IP地址。对于使用动态IP地址的单位来说，如果发现机器无法上网，而计算机从DHCP服务器处获得的IP地址等相关信息不完全，可以将该地址释放。 ipconfig /renew：从DHCP服务器重新获得IP地址。释放了IP地址及相关信息之后，必须重新获得一个IP地址，直接输入此命令之后，便可以从DHCP服务器处获得一个IP地址。如果不用此命令，要想重新获得一个IP地址信息，需要重新启动计算机或注销计算机才行。 shutdown shutdown.exe -a 取消关机 shutdown.exe -s 关机 shutdown.exe -f 强行关闭应用程序。 shutdown.exe -m \\ 计算机名 控制远程计算机。 shutdown.exe -i 显示图形用户界面，但必须是Shutdown的第一个参数。 shutdown.exe -l 注销当前用户。 shutdown.exe -r 关机并重启。 shutdown.exe -t 时间 设置关机倒计时。 shutdown.exe -c”消息内容” 输入关机对话框中的消息内容（不能超127个字符）。 示例： 电脑要在24:00关机 at 24:00 Shutdown -s 倒计时的方式关机 Shutdown.exe -s -t 7200 其他命令 cls ——清屏幕命令 ver 查看系统版本号命令 date 日期设置命令 date[mm——dd——yy] time 系统时钟设置命令 time[hh：mm：ss：xx] mem 显示系统的硬件和操作系统的状况。 mem[/c][/f][/m][/p] msg 显示系统的硬件和操作系统的状况。 msg[/s] tlist -t 以树行列表显示进程（为系统的附加工具，默认是没有安装的，在安装目录的support/tools文件夹内） kill -f 进程名 加-f参数后强制结束某进程（为系统的附加工具，默认是没有安装的，在安装目录的support/tools文件夹内） nbtstat 作用：该命令使用TCP/IP上的NetBIOS显示协议统计和当前TCP/IP连接，使用这个命令你可以得到远程主机的NETBIOS信息，比如用户名、所属的工作组、网卡的MAC地址等。在此我们就有必要了解几个基本的参数。 PS： -a 使用这个参数，只要你知道了远程主机的机器名称，就可以得到它的NETBIOS信息（下同）。 -A 这个参数也可以得到远程主机的NETBIOS信息，但需要你知道它的IP。 -n 列出本地机器的NETBIOS信息。 netstat 作用：这是一个用来查看网络状态的命令，操作简便功能强大。 PS： -a 查看本地机器的所有开放端口，可以有效发现和预防木马，可以知道机器所开的服务等信息 这里可以看出本地机器开放有FTP服务、Telnet服务、邮件服务、WEB服务等。用法：netstat -a IP。 -r 列出当前的路由信息，告诉我们本地机器的网关、子网掩码等信息。用法：netstat -r IP。 tracert 作用：跟踪路由信息，使用此命令可以查出数据从本地机器传输到目标主机所经过的所有途径，这对我们了解网络布局和结构很有帮助。 net 作用：这个命令是网络命令中最重要的一个，必须透彻掌握它的每一个子命令的用法，因为它的功能实在是太强大了在这里，我们重点掌握几个常用的子命令。 net view 使用此命令查看远程主机的所有共享资源。命令格式为net view \\IP。 net use 把远程主机的某个共享资源影射为本地盘符，图形界面方便使用。命令格式为net use x: \\IP\\sharename。 net start 使用它来启动远程主机上的服务。用法：net start servername net stop 入侵后发现远程主机的某个服务碍手碍脚，怎么办？利用这个命令停掉就ok了，用法和net start同。 net user 查看和帐户有关的情况，包括新建帐户、删除帐户、查看特定帐户、激活帐户、帐户禁用等。 PS: net user abcd 1234 /add，新建一个用户名为abcd，密码为1234的帐户，默认为user组成员。 net user abcd /del，将用户名为abcd的用户删除。 net user abcd /active:no，将用户名为abcd的用户禁用。 net user abcd /active:yes，激活用户名为abcd的用户。 net user abcd， 查看用户名为abcd的用户的情况 net localgroup 查看所有和用户组有关的信息和进行相关操作。 net time 这个命令可以查看远程主机当前的时间。 at 作用：这个命令的作用是安排在特定日期或时间执行某个特定的命令和程序。 用法：at time command \\computer ftp 作用：首先在命令行键入ftp回车，出现ftp的提示符，这时候可以键入“help”来查看帮助（任何DOS命令 都可以使用此方法查看其帮助）。 PS: 1.ftp 2.open 主机IP ftp端口 3.录入用户名和密码，就可以进行相应操作了。 dir 跟DOS命令一样，用于查看服务器的文件，直接敲上dir回车，就可以看到此ftp服务器上的文件。 cd 进入某个文件夹。 get 下载文件到本地机器。 put 上传文件到远程服务器。这就要看远程ftp服务器是否给了你可写的权限了，如果可以，呵呵，该怎么 利用就不多说了，大家就自由发挥去吧。 delete 删除远程ftp服务器上的文件。这也必须保证你有可写的权限。 bye 退出当前连接。 quit 同上。 telnet 作用：功能强大的远程登陆命令，几乎所有的入侵者都喜欢用它，屡试不爽。为什么？它操作简单，如同使用自己的机器一样，只要你熟悉DOS命令，在成功以administrator身份连接了远程机器后，就可以用它来**想干的一切了。下面介绍一下使用方法，首先键入telnet回车，再键入help查看其帮助信息。 特殊命令 向上箭头”↑”和向下箭头”↓”—–回看上一次执行的命令 “Ctrl+C” 组合键或”Break”键 —–中断操作 鼠标操作”标记” —————–用来选中文本 鼠标操作”粘贴” —————–用来把剪贴板内容粘贴到提示符下 程序进程 作用：ntsd 是一条dos命令，功能是用于结束一些常规下结束不了的死进程。 使用： 1.利用进程的PID结束进程 命令格式：ntsd -c q -p pid 命令范例：ntsd -c q -p 1332 （结束explorer.exe进程） 2.利用进程名结束进程 命令格式：ntsd -c q -pn .exe （.exe 为进程名，exe不能省） 命令范例：ntsd -c q -pn explorer.exe 3.taskkill结束进程 命令格式：taskkill /pid 1234 /f （ 也可以达到同样的效果） ","link":"https://pandajackpragrammer.github.io/post/dos/"},{"title":"好用的二维码 API 接口_二维码解析接口","content":"使用方法很简单，替换 [http://www.pandajack.top](http://www.pandajack.top/) 为想要生成的文字或链接即可。 https 二维码生成 api (如果二维码不显示，说明接口已失效) 1、搜狐视频提供的二维码 api，已稳定五年以上。 https://my.tv.sohu.com/user/a/wvideo/getQRCode.do?text=https://www.pandajack.top 2、网易 lofter 二维码 api 接口，已稳定五年以上。 https://www.lofter.com/genBitmaxImage?url=https://www.pandajack.top 3、qrserver 提供的二维码 api，国外服务，已稳定五年以上。 https://api.qrserver.com/v1/create-qr-code/?size=150×150&amp;data=https://www.pandajack.top 4、qrcoder 提供的二维码 api，国外服务，已稳定五年以上。 https://www.qrcoder.co.uk/api/v1/?text=https://www.pandajack.top 5、p= 二维码尺寸，可选范围 1-40 已稳定有两年左右。 https://api.isoyu.com/qr/?m=0&amp;e=L&amp;p=10&amp;url=https://www.pandajack.top ","link":"https://pandajackpragrammer.github.io/post/erweimaapi/"}]}